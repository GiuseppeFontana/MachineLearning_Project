{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- tutto salvato con prefisso v01_\n",
    "- classificatore kaggle con batch normalization\n",
    "- split del dataset 0.2 test 0.8 train (di cui 0.1 val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import sklearn.preprocessing as preproc\n",
    "import numpy as np\n",
    "import keras as k\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "from keras.models import Sequential\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#from time import time\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import BatchNormalization\n",
    "import math\n",
    "import shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### variabili globali\n",
    "#### GIUSEPPE\n",
    "#image_path = '..\\skin-cancer-mnist-ham10000\\HAM10000_images_part_1'\n",
    "image_path = '..\\\\..\\\\Untitled_Folder'\n",
    "#### FABIO\n",
    "# image_path = '..\\skin-cancer-mnist-ham10000\\HAM10000_images_part_1'\n",
    "csv_path = 'HAM10000_metadata.csv'\n",
    "csv_completo = 'dataframe_completo.csv'\n",
    "csv_completo_2 = 'dataframe_completo_2.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dal dataframe ne estrae le immagini in un array, serve nel batch\n",
    "def load_images(array):\n",
    "    images = list()\n",
    "    #print(array.iloc[0])\n",
    "    for index in range(0,len(array)):\n",
    "        #print(index.type())\n",
    "        img_id = array.iloc[index]\n",
    "        elem = os.path.join(image_path, img_id)\n",
    "        elem = elem + \".jpg\"\n",
    "        img = cv2.imread(elem)\n",
    "        # TODO va fatto un reshape, non capisco perchÃ©\n",
    "        images.append(np.asarray(img)) #########################################################################################\n",
    "    return np.asarray(images)\n",
    "\n",
    "def my_train_batch(dataset, batch, epochs, classifier):\n",
    "    size = len(dataset)\n",
    "    epoch=0\n",
    "    cl1 = k.models.load_model(classifier)\n",
    "    # train del classificatore un batch alla volta\n",
    "    while size >= batch:\n",
    "        # To get n random rows \n",
    "        samples = dataset.sample(n = batch)\n",
    "        # splitting test and validation\n",
    "        X_train, X_val, y_train, y_val = train_test_split(samples[\"image_id\"], samples[\"dx\"], test_size=0.30)\n",
    "        \n",
    "        train_img = np.asarray(load_images(X_train))\n",
    "        val_img = np.asarray(load_images(X_val))\n",
    "        \n",
    "        #1hot encoder\n",
    "        enc = OneHotEncoder(sparse=False)\n",
    "        y_train_shaped = np.array(y_train).reshape(-1,1)\n",
    "        y_val_shaped = np.array(y_val).reshape(-1,1)\n",
    "        enc.fit(y_train_shaped)\n",
    "        y_train_one = enc.transform(y_train_shaped)\n",
    "        y_val_one = enc.transform(y_val_shaped)\n",
    "        \n",
    "        cl1.fit(train_img, y_train_one, epochs=epochs, shuffle=True, validation_data=(val_img, y_val_one), verbose=1)\n",
    "        \n",
    "        #pulizia memoria e reset per il prossimo ciclo\n",
    "        del X_train, y_train_one, X_val, y_val_one, train_img, val_img\n",
    "        dataset = dataset.drop(samples.index)\n",
    "        size = len(dataset)\n",
    "        del samples, enc\n",
    "        epoch = epoch + 1\n",
    "        print(\"fine epoca \" + str(epoch) + \";\\trestano \" + str(size) + \" campioni nel dataset\")\n",
    "        \n",
    "    ######## ULTIMO CICLO CHE FINISCE IL DATASET\n",
    "    samples = dataset.sample(n = size)\n",
    "    # splitting test and validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(samples[\"image_id\"], samples[\"dx\"], test_size=0.30)\n",
    "    \n",
    "    train_img = np.asarray(load_images(X_train))\n",
    "    val_img = np.asarray(load_images(X_val))\n",
    "    \n",
    "    #1hot encoder\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "    y_train_shaped = np.array(y_train).reshape(-1,1)\n",
    "    y_val_shaped = np.array(y_val).reshape(-1,1)\n",
    "    enc.fit(y_train_shaped)\n",
    "    y_train_one = enc.transform(y_train_shaped)\n",
    "    y_val_one = enc.transform(y_val_shaped)\n",
    "    \n",
    "    cl1.fit(train_img, y_train_one, epochs=epochs, shuffle=True, validation_data=(val_img, y_val_one), verbose=1)\n",
    "    \n",
    "    del X_train, y_train_one, X_val, y_val_one, train_img, val_img\n",
    "    dataset = dataset.drop(samples.index)\n",
    "    size = len(dataset)\n",
    "    del samples, enc\n",
    "    epoch = epoch + 1\n",
    "    print(\"fine ultima epoca\")\n",
    "\n",
    "    cl1.save(classifier)\n",
    "    return\n",
    "\n",
    "def kaggle_classifier():\n",
    "    # Set the CNN model \n",
    "    # my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "    input_shape = (150, 200, 3)\n",
    "    build_shape = (None, 150, 200, 3)\n",
    "    num_classes = 7\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(16, kernel_size=(3, 3),activation='relu',padding = 'Same',input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(16,kernel_size=(3, 3), activation='relu',padding = 'Same',))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.40))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.build(build_shape)\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - dataset splittato 80 20\n",
    "dataset = pd.read_csv(csv_completo_2, encoding = \"ISO-8859-1\")\n",
    "\n",
    "mass = int(len(dataset)*0.8)\n",
    "train = dataset.sample(n=mass)\n",
    "train.to_csv(\"v01_train08.csv\", index=False)\n",
    "test = dataset.drop(train.index)\n",
    "test.to_csv(\"v01_test02.csv\", index=False)\n",
    "\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"v01_train08.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_5 (Batch (None, 150, 200, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 150, 200, 16)      448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 150, 200, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 150, 200, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 75, 100, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 75, 100, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 75, 100, 32)       4640      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 75, 100, 32)       9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 37, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 37, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 59200)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               7577728   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 7,595,363\n",
      "Trainable params: 7,595,325\n",
      "Non-trainable params: 38\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# - creo cl_batch e cl_fit\n",
    "cl_k = kaggle_classifier()\n",
    "cl_k.save('v01_cl_kaggle.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - carico in memoria le immagini\n",
    "# - suddivido in train validation\n",
    "# - 1hot encoding delle y\n",
    "images = load_images(train[\"image_id\"])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, train[\"dx\"], test_size=0.10)\n",
    "\n",
    "#1hot encoder\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "y_train_shaped = np.array(y_train).reshape(-1,1)\n",
    "y_val_shaped = np.array(y_val).reshape(-1,1)\n",
    "enc.fit(y_train_shaped)\n",
    "y_train_one = enc.transform(y_train_shaped)\n",
    "y_val_one = enc.transform(y_val_shaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34527 samples, validate on 3837 samples\n",
      "Epoch 1/5\n",
      "34527/34527 [==============================] - 3704s 107ms/step - loss: 0.3142 - val_loss: 0.2568\n",
      "Epoch 2/5\n",
      "34527/34527 [==============================] - 3670s 106ms/step - loss: 0.2532 - val_loss: 0.2359\n",
      "Epoch 3/5\n",
      "34527/34527 [==============================] - 5256s 152ms/step - loss: 0.2307 - val_loss: 0.2121\n",
      "Epoch 4/5\n",
      "34527/34527 [==============================] - 1520s 44ms/step - loss: 0.2109 - val_loss: 0.2033\n",
      "Epoch 5/5\n",
      "34527/34527 [==============================] - 3192s 92ms/step - loss: 0.1967 - val_loss: 0.2163\n"
     ]
    }
   ],
   "source": [
    "# FIT kaggle\n",
    "cl_name = \"v01_cl_kaggle.h5\"\n",
    "cl_k = k.models.load_model(cl_name)\n",
    "cl_k.fit(X_train, y_train_one, epochs=5, shuffle=True, validation_data=(X_val, y_val_one), verbose=1)\n",
    "cl_k.save(cl_name)\n",
    "\n",
    "del X_train, X_val, y_train, y_val, y_train_shaped, y_val_shaped, y_train_one, y_val_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "              handle_unknown='error', sparse=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ TEST\n",
    "# - carico in memoria il classificatore\n",
    "# - istanzio l'encoder e lo fitto\n",
    "\n",
    "#dataset = pd.read_csv(csv_completo_2, encoding = \"ISO-8859-1\")\n",
    "testset = pd.read_csv(\"v01_test02.csv\", encoding = \"ISO-8859-1\")\n",
    "\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "y_train_shaped = np.array(testset[\"dx\"]).reshape(-1,1)\n",
    "enc.fit(y_train_shaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - carico in memoria le immagini test\n",
    "\n",
    "test_img = load_images(testset[\"image_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.65      0.59      1391\n",
      "           1       0.66      0.60      0.63      1104\n",
      "           2       0.63      0.44      0.52      1567\n",
      "           3       0.85      0.67      0.75      1345\n",
      "           4       0.49      0.81      0.61      1507\n",
      "           5       0.86      0.72      0.79      1329\n",
      "           6       0.98      0.88      0.93      1348\n",
      "\n",
      "    accuracy                           0.68      9591\n",
      "   macro avg       0.72      0.68      0.69      9591\n",
      "weighted avg       0.71      0.68      0.68      9591\n",
      "\n",
      "F1-score: 0.68\n"
     ]
    }
   ],
   "source": [
    "# - predict del classificatore k\n",
    "\n",
    "predictions1 = cl_k.predict(test_img)\n",
    "pred_reverse1 = enc.inverse_transform(predictions1)\n",
    "print(sklearn.metrics.classification_report(testset[\"dx\"], pred_reverse1))\n",
    "print('F1-score: '+ str(round(sklearn.metrics.f1_score(testset[\"dx\"], pred_reverse1, average='micro'),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
