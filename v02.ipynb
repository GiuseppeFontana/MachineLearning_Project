{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- tutto salvato con prefisso v02_\n",
    "- classificatore kaggle con batch normalization\n",
    "- train in entrambi i modi su un dataset complessivo di 21k campioni; fit con tante epoche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import sklearn.preprocessing as preproc\n",
    "import numpy as np\n",
    "import keras as k\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "from keras.models import Sequential\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#from time import time\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import BatchNormalization\n",
    "import math\n",
    "import shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### variabili globali\n",
    "#### GIUSEPPE\n",
    "#image_path = '..\\skin-cancer-mnist-ham10000\\HAM10000_images_part_1'\n",
    "image_path = '..\\\\..\\\\Untitled_Folder'\n",
    "#### FABIO\n",
    "# image_path = '..\\skin-cancer-mnist-ham10000\\HAM10000_images_part_1'\n",
    "csv_path = 'HAM10000_metadata.csv'\n",
    "csv_completo_2 = 'dataframe_completo_2.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dal dataframe ne estrae le immagini in un array, serve nel batch\n",
    "def load_images(array):\n",
    "    images = list()\n",
    "    #print(array.iloc[0])\n",
    "    for index in range(0,len(array)):\n",
    "        #print(index.type())\n",
    "        img_id = array.iloc[index]\n",
    "        elem = os.path.join(image_path, img_id)\n",
    "        elem = elem + \".jpg\"\n",
    "        img = cv2.imread(elem)\n",
    "        # TODO va fatto un reshape, non capisco perchÃ©\n",
    "        images.append(np.asarray(img)) #########################################################################################\n",
    "    return np.asarray(images)\n",
    "\n",
    "def my_train_batch(dataset, batch, epochs, classifier):\n",
    "    size = len(dataset)\n",
    "    epoch=0\n",
    "    cl1 = k.models.load_model(classifier)\n",
    "    # train del classificatore un batch alla volta\n",
    "    while size >= batch:\n",
    "        # To get n random rows \n",
    "        samples = dataset.sample(n = batch)\n",
    "        # splitting test and validation\n",
    "        X_train, X_val, y_train, y_val = train_test_split(samples[\"image_id\"], samples[\"dx\"], test_size=0.30)\n",
    "        \n",
    "        train_img = np.asarray(load_images(X_train))\n",
    "        val_img = np.asarray(load_images(X_val))\n",
    "        \n",
    "        #1hot encoder\n",
    "        enc = OneHotEncoder(sparse=False)\n",
    "        y_train_shaped = np.array(y_train).reshape(-1,1)\n",
    "        y_val_shaped = np.array(y_val).reshape(-1,1)\n",
    "        enc.fit(y_train_shaped)\n",
    "        y_train_one = enc.transform(y_train_shaped)\n",
    "        y_val_one = enc.transform(y_val_shaped)\n",
    "        \n",
    "        cl1.fit(train_img, y_train_one, epochs=epochs, shuffle=True, validation_data=(val_img, y_val_one), verbose=1)\n",
    "        \n",
    "        #pulizia memoria e reset per il prossimo ciclo\n",
    "        del X_train, y_train_one, X_val, y_val_one, train_img, val_img\n",
    "        dataset = dataset.drop(samples.index)\n",
    "        size = len(dataset)\n",
    "        del samples, enc\n",
    "        epoch = epoch + 1\n",
    "        print(\"fine epoca \" + str(epoch) + \";\\trestano \" + str(size) + \" campioni nel dataset\")\n",
    "        \n",
    "    ######## ULTIMO CICLO CHE FINISCE IL DATASET\n",
    "    samples = dataset.sample(n = size)\n",
    "    # splitting test and validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(samples[\"image_id\"], samples[\"dx\"], test_size=0.30)\n",
    "    \n",
    "    train_img = np.asarray(load_images(X_train))\n",
    "    val_img = np.asarray(load_images(X_val))\n",
    "    \n",
    "    #1hot encoder\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "    y_train_shaped = np.array(y_train).reshape(-1,1)\n",
    "    y_val_shaped = np.array(y_val).reshape(-1,1)\n",
    "    enc.fit(y_train_shaped)\n",
    "    y_train_one = enc.transform(y_train_shaped)\n",
    "    y_val_one = enc.transform(y_val_shaped)\n",
    "    \n",
    "    cl1.fit(train_img, y_train_one, epochs=epochs, shuffle=True, validation_data=(val_img, y_val_one), verbose=1)\n",
    "    \n",
    "    del X_train, y_train_one, X_val, y_val_one, train_img, val_img\n",
    "    dataset = dataset.drop(samples.index)\n",
    "    size = len(dataset)\n",
    "    del samples, enc\n",
    "    epoch = epoch + 1\n",
    "    print(\"fine ultima epoca\")\n",
    "\n",
    "    cl1.save(classifier)\n",
    "    return\n",
    "\n",
    "def kaggle_classifier():\n",
    "    # Set the CNN model \n",
    "    # my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "    input_shape = (150, 200, 3)\n",
    "    build_shape = (None, 150, 200, 3)\n",
    "    num_classes = 7\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(16, kernel_size=(3, 3),activation='relu',padding = 'Same',input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(16,kernel_size=(3, 3), activation='relu',padding = 'Same',))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.40))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.build(build_shape)\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting class 0\n",
      "starting class 1\n",
      "starting class 2\n",
      "starting class 3\n",
      "starting class 4\n",
      "starting class 5\n",
      "starting class 6\n"
     ]
    }
   ],
   "source": [
    "# creazione dataset piccolo\n",
    "size = 3000\n",
    "\n",
    "dataset = pd.read_csv(csv_completo_2, encoding = \"ISO-8859-1\")\n",
    "new_data = pd.DataFrame()\n",
    "for elem in range(7):\n",
    "    print(\"starting class \" + str(elem))\n",
    "    samples = dataset[dataset[\"dx\"] == elem].sample(n=size)\n",
    "    new_data = new_data.append(samples)\n",
    "new_data.to_csv('v02_dataframe_piccolo.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - dataset splittato 80 20\n",
    "dataset = new_data\n",
    "\n",
    "mass = int(len(dataset)*0.8)\n",
    "train = dataset.sample(n=mass)\n",
    "train.to_csv(\"v02_train08.csv\", index=False)\n",
    "test = dataset.drop(train.index)\n",
    "test.to_csv(\"v02_test02.csv\", index=False)\n",
    "\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"v02_train08.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 150, 200, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 150, 200, 16)      448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 150, 200, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 150, 200, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 75, 100, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75, 100, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 75, 100, 32)       4640      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 75, 100, 32)       9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 37, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 37, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 59200)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               7577728   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 7,595,363\n",
      "Trainable params: 7,595,325\n",
      "Non-trainable params: 38\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# - creo cl_batch e cl_fit\n",
    "cl_k = kaggle_classifier()\n",
    "cl_k.save('v02_cl_kaggle_fit.h5')\n",
    "cl_k.save('v02_cl_kaggle_batch.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - carico in memoria le immagini\n",
    "# - suddivido in train validation\n",
    "# - 1hot encoding delle y\n",
    "images = load_images(train[\"image_id\"])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, train[\"dx\"], test_size=0.10)\n",
    "\n",
    "#1hot encoder\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "y_train_shaped = np.array(y_train).reshape(-1,1)\n",
    "y_val_shaped = np.array(y_val).reshape(-1,1)\n",
    "enc.fit(y_train_shaped)\n",
    "y_train_one = enc.transform(y_train_shaped)\n",
    "y_val_one = enc.transform(y_val_shaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15120 samples, validate on 1680 samples\n",
      "Epoch 1/50\n",
      "15120/15120 [==============================] - 581s 38ms/step - loss: 0.3538 - val_loss: 0.2974\n",
      "Epoch 2/50\n",
      "15120/15120 [==============================] - 638s 42ms/step - loss: 0.2934 - val_loss: 0.2657\n",
      "Epoch 3/50\n",
      "15120/15120 [==============================] - 585s 39ms/step - loss: 0.2732 - val_loss: 0.2566\n",
      "Epoch 4/50\n",
      "15120/15120 [==============================] - 583s 39ms/step - loss: 0.2541 - val_loss: 0.2418\n",
      "Epoch 5/50\n",
      "15120/15120 [==============================] - 577s 38ms/step - loss: 0.2395 - val_loss: 0.2186\n",
      "Epoch 6/50\n",
      "15120/15120 [==============================] - 647s 43ms/step - loss: 0.2228 - val_loss: 0.2490\n",
      "Epoch 7/50\n",
      "15120/15120 [==============================] - 598s 40ms/step - loss: 0.2082 - val_loss: 0.2131\n",
      "Epoch 8/50\n",
      "15120/15120 [==============================] - 607s 40ms/step - loss: 0.1934 - val_loss: 0.2178\n",
      "Epoch 9/50\n",
      "15120/15120 [==============================] - 607s 40ms/step - loss: 0.1798 - val_loss: 0.2105\n",
      "Epoch 10/50\n",
      "15120/15120 [==============================] - 606s 40ms/step - loss: 0.1668 - val_loss: 0.2107\n",
      "Epoch 11/50\n",
      "15120/15120 [==============================] - 607s 40ms/step - loss: 0.1566 - val_loss: 0.2264\n",
      "Epoch 12/50\n",
      "15120/15120 [==============================] - 605s 40ms/step - loss: 0.1497 - val_loss: 0.2476\n",
      "Epoch 13/50\n",
      "15120/15120 [==============================] - 606s 40ms/step - loss: 0.1396 - val_loss: 0.2231\n",
      "Epoch 14/50\n",
      "15120/15120 [==============================] - 608s 40ms/step - loss: 0.1306 - val_loss: 0.2109\n",
      "Epoch 15/50\n",
      "15120/15120 [==============================] - 606s 40ms/step - loss: 0.1241 - val_loss: 0.2169\n",
      "Epoch 16/50\n",
      "15120/15120 [==============================] - 605s 40ms/step - loss: 0.1184 - val_loss: 0.2785\n",
      "Epoch 17/50\n",
      "15120/15120 [==============================] - 607s 40ms/step - loss: 0.1142 - val_loss: 0.2455\n",
      "Epoch 18/50\n",
      "15120/15120 [==============================] - 603s 40ms/step - loss: 0.1088 - val_loss: 0.2710\n",
      "Epoch 19/50\n",
      "15120/15120 [==============================] - 600s 40ms/step - loss: 0.1099 - val_loss: 0.2880\n",
      "Epoch 20/50\n",
      "15120/15120 [==============================] - 599s 40ms/step - loss: 0.1072 - val_loss: 0.2783\n",
      "Epoch 21/50\n",
      "15120/15120 [==============================] - 598s 40ms/step - loss: 0.1011 - val_loss: 0.2541\n",
      "Epoch 22/50\n",
      "15120/15120 [==============================] - 596s 39ms/step - loss: 0.1046 - val_loss: 0.2509\n",
      "Epoch 23/50\n",
      "15120/15120 [==============================] - 595s 39ms/step - loss: 0.1005 - val_loss: 0.2860\n",
      "Epoch 24/50\n",
      "15120/15120 [==============================] - 594s 39ms/step - loss: 0.1020 - val_loss: 0.2361\n",
      "Epoch 25/50\n",
      "15120/15120 [==============================] - 594s 39ms/step - loss: 0.0998 - val_loss: 0.2878\n",
      "Epoch 26/50\n",
      "15120/15120 [==============================] - 596s 39ms/step - loss: 0.0986 - val_loss: 0.3072\n",
      "Epoch 27/50\n",
      "15120/15120 [==============================] - 596s 39ms/step - loss: 0.1030 - val_loss: 0.3411\n",
      "Epoch 28/50\n",
      "15120/15120 [==============================] - 594s 39ms/step - loss: 0.1003 - val_loss: 0.3219\n",
      "Epoch 29/50\n",
      "15120/15120 [==============================] - 596s 39ms/step - loss: 0.0980 - val_loss: 0.2756\n",
      "Epoch 30/50\n",
      "15120/15120 [==============================] - 596s 39ms/step - loss: 0.0963 - val_loss: 0.2655\n",
      "Epoch 31/50\n",
      "15120/15120 [==============================] - 592s 39ms/step - loss: 0.0970 - val_loss: 0.3317\n",
      "Epoch 32/50\n",
      "15120/15120 [==============================] - 596s 39ms/step - loss: 0.0947 - val_loss: 0.2511\n",
      "Epoch 33/50\n",
      "15120/15120 [==============================] - 596s 39ms/step - loss: 0.0966 - val_loss: 0.2921\n",
      "Epoch 34/50\n",
      "15120/15120 [==============================] - 595s 39ms/step - loss: 0.0925 - val_loss: 0.2796\n",
      "Epoch 35/50\n",
      "15120/15120 [==============================] - 598s 40ms/step - loss: 0.0926 - val_loss: 0.2665\n",
      "Epoch 36/50\n",
      "15120/15120 [==============================] - 597s 39ms/step - loss: 0.0949 - val_loss: 0.2817\n",
      "Epoch 37/50\n",
      "15120/15120 [==============================] - 594s 39ms/step - loss: 0.0903 - val_loss: 0.3737\n",
      "Epoch 38/50\n",
      "15120/15120 [==============================] - 598s 40ms/step - loss: 0.0987 - val_loss: 0.2863\n",
      "Epoch 39/50\n",
      "15120/15120 [==============================] - 597s 40ms/step - loss: 0.0933 - val_loss: 0.2714\n",
      "Epoch 40/50\n",
      "15120/15120 [==============================] - 612s 40ms/step - loss: 0.0926 - val_loss: 0.3751\n",
      "Epoch 41/50\n",
      "15120/15120 [==============================] - 604s 40ms/step - loss: 0.0933 - val_loss: 0.2998\n",
      "Epoch 42/50\n",
      "15120/15120 [==============================] - 600s 40ms/step - loss: 0.0973 - val_loss: 0.2626\n",
      "Epoch 43/50\n",
      "15120/15120 [==============================] - 599s 40ms/step - loss: 0.1029 - val_loss: 0.2634\n",
      "Epoch 44/50\n",
      "15120/15120 [==============================] - 602s 40ms/step - loss: 0.0985 - val_loss: 0.2566\n",
      "Epoch 45/50\n",
      "15120/15120 [==============================] - 600s 40ms/step - loss: 0.0962 - val_loss: 0.2655\n",
      "Epoch 46/50\n",
      "15120/15120 [==============================] - 599s 40ms/step - loss: 0.0996 - val_loss: 0.3266\n",
      "Epoch 47/50\n",
      "15120/15120 [==============================] - 601s 40ms/step - loss: 0.0951 - val_loss: 0.2769\n",
      "Epoch 48/50\n",
      "15120/15120 [==============================] - 600s 40ms/step - loss: 0.0996 - val_loss: 0.4530\n",
      "Epoch 49/50\n",
      "15120/15120 [==============================] - 598s 40ms/step - loss: 0.0989 - val_loss: 0.2734\n",
      "Epoch 50/50\n",
      "15120/15120 [==============================] - 601s 40ms/step - loss: 0.1049 - val_loss: 0.4033\n"
     ]
    }
   ],
   "source": [
    "# kaggle fit\n",
    "cl_name = \"v02_cl_kaggle_fit.h5\"\n",
    "cl_k = k.models.load_model(cl_name)\n",
    "cl_k.fit(X_train, y_train_one, epochs=50, shuffle=True, validation_data=(X_val, y_val_one), verbose=1)\n",
    "cl_k.save(cl_name)\n",
    "\n",
    "del X_train, X_val, y_train, y_val, y_train_shaped, y_val_shaped, y_train_one, y_val_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "              handle_unknown='error', sparse=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ TEST\n",
    "# - carico in memoria il classificatore\n",
    "# - istanzio l'encoder e lo fitto\n",
    "\n",
    "#dataset = pd.read_csv(csv_completo_2, encoding = \"ISO-8859-1\")\n",
    "testset = pd.read_csv(\"v02_test02.csv\", encoding = \"ISO-8859-1\")\n",
    "\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "y_train_shaped = np.array(testset[\"dx\"]).reshape(-1,1)\n",
    "enc.fit(y_train_shaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - carico in memoria le immagini test\n",
    "\n",
    "test_img = load_images(testset[\"image_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.60      0.55       581\n",
      "           1       0.62      0.57      0.59       585\n",
      "           2       0.51      0.43      0.47       622\n",
      "           3       0.62      0.82      0.70       588\n",
      "           4       0.60      0.60      0.60       625\n",
      "           5       0.83      0.75      0.79       595\n",
      "           6       0.98      0.85      0.91       604\n",
      "\n",
      "    accuracy                           0.66      4200\n",
      "   macro avg       0.67      0.66      0.66      4200\n",
      "weighted avg       0.67      0.66      0.66      4200\n",
      "\n",
      "F1-score: 0.66\n"
     ]
    }
   ],
   "source": [
    "# - predict del classificatore k\n",
    "\n",
    "predictions1 = cl_k.predict(test_img)\n",
    "pred_reverse1 = enc.inverse_transform(predictions1)\n",
    "print(sklearn.metrics.classification_report(testset[\"dx\"], pred_reverse1))\n",
    "print('F1-score: '+ str(round(sklearn.metrics.f1_score(testset[\"dx\"], pred_reverse1, average='micro'),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - FIT di cl_batch su train\n",
    "cl_name = 'v02_cl_kaggle_batch.h5'\n",
    "my_train_batch(dataset=train, batch=2000, epochs=10, classifier = cl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - predict del kaggle batch\n",
    "cl_k = k.models.load_model(cl_name)\n",
    "predictions2 = cl_k.predict(test_img)\n",
    "pred_reverse2 = enc.inverse_transform(predictions2)\n",
    "print(sklearn.metrics.classification_report(testset[\"dx\"], pred_reverse2))\n",
    "print('F1-score: '+ str(round(sklearn.metrics.f1_score(testset[\"dx\"], pred_reverse2, average='micro'),2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
