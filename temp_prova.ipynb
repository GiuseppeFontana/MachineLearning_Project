{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import sklearn as skl\n",
    "import sklearn.preprocessing as preproc\n",
    "import numpy as np\n",
    "import keras as k\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#from time import time\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import math\n",
    "import shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "#### variabili globali\n",
    "#### GIUSEPPE\n",
    "image_path = '..\\skin-cancer-mnist-ham10000\\HAM10000_images_part_1'\n",
    "#### FABIO\n",
    "# image_path = '..\\skin-cancer-mnist-ham10000\\HAM10000_images_part_1'\n",
    "csv_path = 'HAM10000_metadata.csv'\n",
    "csv_completo = 'dataframe_completo.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(csv_completo, encoding = \"ISO-8859-1\")\n",
    "batch = 1000\n",
    "\n",
    "def my_train_batch(dataset=dataset, batch=500, classifier='classifier1.h5'):\n",
    "    size = len(dataset)\n",
    "    epoch=0\n",
    "    while size >= batch:\n",
    "        # To get n random rows \n",
    "        samples = dataset.sample(n = batch)\n",
    "        # splitting test and validation\n",
    "        X_train, X_test1, y_train, y_test1 = train_test_split(samples[\"image_id\"], samples[\"dx\"], test_size=0.30)\n",
    "        X_test, X_val, y_test, y_val = train_test_split(X_test1, y_test1, test_size=0.40)\n",
    "        del X_test1, y_test1\n",
    "        \n",
    "        train_img = np.asarray(load_images(X_train))\n",
    "        test_img = np.asarray(load_images(X_test))  # NB non sono mai usate, pensare se servano oppure no\n",
    "        val_img = np.asarray(load_images(X_val))\n",
    "        \n",
    "        \n",
    "        #X_bad_id = X_bad_id.reshape((X_bad_id.shape[0], 1))\n",
    "        cl1 = k.models.load_model('classifier2.h5')\n",
    "        cl1.fit(train_img, y_train, epochs=1, shuffle=True, validation_data=(val_img, y_val), verbose=2)\n",
    "        cl1.save('classifier1.h5')\n",
    "        del X_train, y_train, X_test, y_test, X_val, y_val, train_img, test_img, val_img, classifier\n",
    "        dataset = dataset.drop(samples.index)\n",
    "        size = len(dataset)\n",
    "        del samples\n",
    "        epoch = epoch + 1\n",
    "        print(\"fine epoca \" + epoch + \";\\trestano \" + size + \"campioni nel dataset\")\n",
    "    return\n",
    "\n",
    "# dal dataframe ne estrae le immagini in un array, serve nel batch\n",
    "def load_images(array):\n",
    "    images = list()\n",
    "    #print(array.iloc[0])\n",
    "    for index in range(0,len(array)):\n",
    "        #print(index.type())\n",
    "        img_id = array.iloc[index]\n",
    "        elem = os.path.join(\"..\\skin-cancer-mnist-ham10000\\HAM10000_images_part_1\", img_id)\n",
    "        elem = elem + \".jpg\"\n",
    "        img = cv2.imread(elem)\n",
    "        # TODO va fatto un reshape, non capisco perché\n",
    "        images.append(np.asarray(img)) #########################################################################################\n",
    "    return images\n",
    "\n",
    "def new_classifier1():\n",
    "    input_img = Input(shape=(450, 600, 3))  # 3x600x450 image RGB \n",
    "    #print (tf.shape(input_img))\n",
    "    x = Conv2D(20, (5, 5), activation='relu', padding='same')(input_img) # 20x450x600\n",
    "    #print (tf.shape(x))\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x) # 20x225x300\n",
    "    #print (tf.shape(x))\n",
    "    x = Conv2D(140, (3, 3), activation='relu', padding='same')(x) # 140x75x100\n",
    "    #print (tf.shape(x))\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x) # 40x38x50\n",
    "    #print (tf.shape(x))\n",
    "    x = Conv2D(50, (3, 3), activation='relu', padding='same')(x) # 50x38x50\n",
    "    #print (tf.shape(x))\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x) # 50x19x25\n",
    "    #print (tf.shape(x))\n",
    "    x = Flatten()(x) # qui la x diventa monodimensionale\n",
    "    #print (tf.shape(x))\n",
    "    # da qualche parte ci va il numero delle label?\n",
    "    encoded = Dense(7, activation='softmax')(x)\n",
    "    classifier = k.models.Model(input_img, encoded)   #questo è il nostro base_estimator, compile configura per il training\n",
    "    classifier.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    #classifier.compile(optimizer='adadelta', loss='categorical_crossentropy') # <- variante che non risolve il problema del dense\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### inizializzazione classificatore sul disco\n",
    "cl1 = new_classifier1()\n",
    "cl1.save('classifier2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = dataset.sample(n=2000)\n",
    "my_train_batch(dataset=samples, batch=batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
