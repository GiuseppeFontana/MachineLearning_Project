{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creazione split\n",
    "#feat_train, feat_test, target_train, target_test = train_test_split(X, y, test_size=0.20, random_state=28) \n",
    "#smote = SMOTENC(sampling_strategy='dict', categorical_features=['bkl', 'vasc'])\n",
    "#X_sm, y_sm = smote.fit_sample(X,y)\n",
    "#len(X)\n",
    "#len(X_sm)\n",
    "\n",
    "\n",
    "#print(type(X))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##############################\n",
    "########## TODO ##############\n",
    "##############################\n",
    "- suddivido le immagini in cartelle per categoria\n",
    "- sistemo il dataframe con sole nomi immagini e dx\n",
    "- per ogni dx:\n",
    "\t- calcolo quanto augmentation devo fare\n",
    "            per ogni categoria:\n",
    "                x = n° immagini in categoria\n",
    "                y = n° immagini nv\n",
    "                n° repliche per immagine = ceil((y-x)/x)\n",
    "\t- per ogni immagine:\n",
    "\t\t- la carico in memoria\n",
    "\t\t- flow, salvando le augmented\n",
    "\t\t- chiudo l'immagine (es. del x)\n",
    "- aggiungo al dataframe la nuova tupla di augmented\n",
    "- salvo il nuovo dataframe                            (fatto fin qua)\n",
    "\n",
    "\n",
    "os.replace(\"path/to/current/file.foo\", \"path/to/new/destination/for/file.foo\")\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Fit the model\n",
    "epochs = 50 \n",
    "batch_size = 10\n",
    "history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (x_validate,y_validate),\n",
    "                              verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])\n",
    "\n",
    "batch():\n",
    "    carico l'insieme di immagini\n",
    "    generator di varianti\n",
    "    fit\n",
    "    chiudo le immagini\n",
    "    pulisco memoria delle varianti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#import sklearn as skl\n",
    "import sklearn.preprocessing as preproc\n",
    "import numpy as np\n",
    "import keras as k\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#from time import time\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import math\n",
    "import shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### variabili globali\n",
    "#### GIUSEPPE\n",
    "image_path = '..\\skin-cancer-mnist-ham10000\\HAM10000_images_part_1'\n",
    "#### FABIO\n",
    "# image_path = '..\\skin-cancer-mnist-ham10000\\HAM10000_images_part_1'\n",
    "csv_path = 'HAM10000_metadata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## API varie\n",
    "# - carica in memoria immagini e label\n",
    "# - 1-hot encoding\n",
    "# - implementazione modello tramite ensamble (nel classificatore va incluso il numero di labels)\n",
    "# - train e test usando il bagging, ma prima bisogna fare SMOTE su vasc e bkl?\n",
    "\n",
    "###############################\n",
    "#############################\n",
    "###### NON SERVONO\n",
    "# carica tutto in un nuovo dataframe\n",
    "#def load_pictures(path, dataset):\n",
    "#    col=[\"lesion_id\" ,\"image_id\",\"dx\",\"dx_type\" ,\"age\" ,\"sex\" ,\"localization\",\"path\",\"pixels\"]\n",
    "#    dataset.insert(7,\"path\",None)\n",
    "#    dataset.insert(8,\"pixels\",None)\n",
    "#    data=pd.DataFrame(columns=col)\n",
    "#    helper = pd.DataFrame(columns=col)\n",
    "#    for _,_,files in os.walk(path+'\\\\'):\n",
    "#        for file in files: \n",
    "#            file_replace = file.replace(\".jpg\", \"\") #tagliare il .jpg che non compare nel dataset\n",
    "#            path2=path+\"\\\\\"+file #path completo di un file\n",
    "#            helper=dataset.loc[dataset[\"image_id\"]==file_replace] #tupla del file\n",
    "#            helper[\"path\"]=path2\n",
    "#            col=[\"lesion_id\" ,\"image_id\",\"dx\",\"dx_type\" ,\"age\" ,\"sex\" ,\"localization\"]\n",
    "#            data = data.append(helper)\n",
    "#    data[\"pixels\"]=data['path'].map(lambda x: np.asarray(Image.open(x).resize((200,150)))) #associazione ai pixel\n",
    "#    return data\n",
    "#\n",
    "#\n",
    "#def onehot_encode(dataset):\n",
    "#    dataset_LabEncoded = lab_encode(dataset)\n",
    "#    x=np.array([dataset_LabEncoded[\"dx\"]]) \n",
    "#    y_onehot = ohe.fit_transform(x.reshape(-1,1))\n",
    "#    return y_onehot\n",
    "#\n",
    "#\n",
    "## si prende tutto l'array di risultati\n",
    "#def reverse_onehot(vector):\n",
    "#    res = ohe.inverse_transform(vector)\n",
    "#    return res\n",
    "#\n",
    "#\n",
    "## conteggio statistiche dataset\n",
    "#def stats(dataset):\n",
    "#    labels = set(dataset['dx'])\n",
    "#    for label in labels:\n",
    "#        print(str(label), ':\\t', str(dataset[dataset['dx']==label]['dx'].count()))\n",
    "#        #print (label)\n",
    "#        \n",
    "#def ensemble():\n",
    "#    #da settare \n",
    "#    #    base_estimator il classificatore come CNN,\n",
    "#    #    n_estimators,\n",
    "#    #    max_samples è il numero di elementi nei training set,\n",
    "#    #    bootstrap se lo vogliamo o no (booleano),\n",
    "#    #    n_jobs per il parallelismo,\n",
    "#    classifier = new_classifier2()\n",
    "#    bagging = BaggingClassifier(base_estimator=classifier, n_estimators=1, \n",
    "#                                bootstrap=True, n_jobs=4)\n",
    "#    return bagging\n",
    "###################################\n",
    "####################################\n",
    "\n",
    "def lab_encode(dataset, le):#Ho una sola colonna! \n",
    "    new_ds = dataset\n",
    "    new_ds[\"dx\"] = le.fit_transform(dataset[\"dx\"])  \n",
    "    return new_ds\n",
    "\n",
    "def lab_decode(dataset, le):\n",
    "    new_ds = dataset\n",
    "    new_ds[\"dx\"] = le.inverse_transform(dataset[\"dx\"])  \n",
    "    return new_ds\n",
    "\n",
    "# conteggio statistiche dataset\n",
    "def stats(dataset):\n",
    "    labels = set(dataset['dx'])\n",
    "    for label in labels:\n",
    "        print(str(label), ':\\t', str(dataset[dataset['dx']==label]['dx'].count()))\n",
    "        #if label != \"nv\":\n",
    "        #    x = dataset[dataset['dx']==label]['dx'].count()\n",
    "        #    y = dataset[dataset['dx']==\"nv\"]['dx'].count()\n",
    "        #    print(\"ugmented per image: \", str(math.floor((y-x)/x)))\n",
    "        x = dataset[dataset['dx']==label]['dx'].count()\n",
    "        y = dataset[dataset['dx']==5]['dx'].count()\n",
    "        value = math.floor((y-x)/x)\n",
    "        print(\"ugmented per image: \", str(value))\n",
    "        aug_size[label] = value\n",
    "        #print (label)\n",
    "\n",
    "        \n",
    "        \n",
    "def new_classifier():\n",
    "    input_img = Input(shape=(450, 600, 3))  # 3x600x450 image RGB \n",
    "    #print (tf.shape(input_img))\n",
    "    x = Conv2D(20, (5, 5), activation='relu', padding='same')(input_img) # 20x450x600\n",
    "    #print (tf.shape(x))\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x) # 20x225x300\n",
    "    #print (tf.shape(x))\n",
    "    x = Conv2D(140, (3, 3), activation='relu', padding='same')(x) # 140x75x100\n",
    "    #print (tf.shape(x))\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x) # 40x38x50\n",
    "    #print (tf.shape(x))\n",
    "    x = Conv2D(50, (3, 3), activation='relu', padding='same')(x) # 50x38x50\n",
    "    #print (tf.shape(x))\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x) # 50x19x25\n",
    "    #print (tf.shape(x))\n",
    "    x = Flatten()(x) # qui la x diventa monodimensionale\n",
    "    #print (tf.shape(x))\n",
    "    # da qualche parte ci va il numero delle label?\n",
    "    encoded = Dense(7, activation='softmax')(x)\n",
    "    classifier = k.models.Model(input_img, encoded)   #questo è il nostro base_estimator, compile configura per il training\n",
    "    classifier.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    return classifier\n",
    "\n",
    "def new_classifier2():\n",
    "    # Set the CNN model \n",
    "    input_shape = (450, 600, 3)\n",
    "    num_classes = 7\n",
    "    \n",
    "    model = k.models.Sequential()\n",
    "    model.add(Conv2D(20, kernel_size=(5, 5),activation='relu',padding = 'Same', input_shape = input_shape))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(140,kernel_size=(3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(50,kernel_size=(3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "def new_classifier3():\n",
    "    # Set the CNN model \n",
    "    input_shape = (150, 200, 3)\n",
    "    num_classes = 7\n",
    "    \n",
    "    model = k.models.Sequential()\n",
    "    model.add(Conv2D(20, kernel_size=(5, 5),activation='relu',padding = 'Same', input_shape = input_shape))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(140,kernel_size=(3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(50,kernel_size=(3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "def initialize_dataset():\n",
    "    dataset = pd.read_csv(csv_path, encoding = \"ISO-8859-1\")\n",
    "    labels = set(dataset[\"dx\"])\n",
    "    new_ds = pd.DataFrame(dataset)\n",
    "    columns=[\"lesion_id\", \"dx_type\", \"age\", \"sex\", \"localization\"]\n",
    "    new_ds = new_ds.drop(columns=columns, axis=0)\n",
    "    return new_ds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ INIZIALIZZAZIONE\n",
    "#creazione dataframe\n",
    "ds, labels = initialize_dataset()\n",
    "# encoding delle labels (dx)\n",
    "encoder = preproc.LabelEncoder()\n",
    "encoded = lab_encode(ds, encoder)\n",
    "encoded = encoded.sort_index()\n",
    "\n",
    "aug_size = [0,0,0,0,0,0,0]\n",
    "\n",
    "# Create a data generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    #brightness_range=(0.9,1.1),\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\t 327\n",
      "ugmented per image:  19\n",
      "1 :\t 514\n",
      "ugmented per image:  12\n",
      "2 :\t 1099\n",
      "ugmented per image:  5\n",
      "3 :\t 115\n",
      "ugmented per image:  57\n",
      "4 :\t 1113\n",
      "ugmented per image:  5\n",
      "5 :\t 6705\n",
      "ugmented per image:  0\n",
      "6 :\t 142\n",
      "ugmented per image:  46\n"
     ]
    }
   ],
   "source": [
    "stats(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#img: 115\n",
      "#img: 1113\n",
      "#img: 142\n"
     ]
    }
   ],
   "source": [
    "##### creazione augmented\n",
    "\n",
    "# note that we are not augmenting class 'nv'\n",
    "#class_list = ['0','1','2','3','4','6']\n",
    "class_list = ['3','4','6']\n",
    "\n",
    "aug_dir = '..\\\\aug_dir'\n",
    "img_dir = os.path.join(aug_dir, 'img_dir')    \n",
    "\n",
    "\n",
    "# Choose a class\n",
    "for img_class in class_list:\n",
    "    \n",
    "    # creazione cartelle contenenti le augmented\n",
    "    dst_class_dir = os.path.join(img_dir, img_class)\n",
    "    os.mkdir(dst_class_dir)\n",
    "    \n",
    "    \n",
    "    # list all images in that directory\n",
    "    src_class_dir = os.path.join('..\\\\skin-cancer-mnist-ham10000\\\\HAM10000_images_part_1', img_class)\n",
    "    img_list = os.listdir(src_class_dir) # qui le immagini sono già nelle proprie cartelle\n",
    "    print('#img: '+ str(len(img_list)))\n",
    "    \n",
    "    # per ogni immagine devo creare le augmented\n",
    "    for fname in img_list:\n",
    "        fpath = os.path.join(src_class_dir, fname)\n",
    "        img = Image.open(fpath)  # this is a PIL image\n",
    "        x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "        x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "        \n",
    "        prefix = fname.replace(\".jpg\", \"\")\n",
    "        # the .flow() command below generates batches of randomly transformed images\n",
    "        # and saves the results to the `preview/` directory\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1,\n",
    "                                  save_to_dir=dst_class_dir, save_prefix=prefix , save_format='jpg'):\n",
    "            i += 1\n",
    "            if i > aug_size[int(img_class)]:\n",
    "                break  # otherwise the generator would loop indefinitely\n",
    "        \n",
    "        del x\n",
    "        img.close()\n",
    "    # run the generator and create about 6000 augmented images\n",
    "    #for i in range(0,num_batches):\n",
    "    #\n",
    "    #    imgs, labels = next(aug_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## sistemazione nuovo dataset\n",
    "aug_dir = '..\\\\aug_dir'\n",
    "img_dir = os.path.join(aug_dir, 'img_dir') \n",
    "classes = os.listdir(img_dir)\n",
    "\n",
    "columns = encoded.columns\n",
    "tupla = pd.DataFrame(columns=columns)\n",
    "index = 10015\n",
    "\n",
    "for elem1 in classes:\n",
    "    class_dir = os.path.join(img_dir, elem1)\n",
    "    images = os.listdir(class_dir)\n",
    "    for elem2 in images:\n",
    "        elem2 = elem2.replace('.jpg', '')\n",
    "        tupla = tupla.append({'image_id': elem2, 'dx': int(elem1)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvataggio (punto 1.2)\n",
    "#dataset.to_csv('Pokemon_clean.csv', index=False) \n",
    "encoded = encoded.append(tupla)\n",
    "encoded.to_csv('dataframe_completo.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_id    ISIC_0029278_0_9941\n",
       "dx                            1\n",
       "Name: 9984, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.iloc[20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# da provare\n",
    "#X = encoded[\"pixels\"]\n",
    "#y = encoded[\"dx\"]\n",
    "#bag_class = ensemble()\n",
    "#X = np.asarray(X)\n",
    "#y = np.asarray(y)\n",
    "#\n",
    "#dataset_size = len(X)\n",
    "#reshaped = np.reshape(X,(dataset_size,-1))\n",
    "#params = bag_class.get_params()\n",
    "#bag_class.fit(reshaped, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 150, 200, 20)      1520      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 75, 100, 20)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 75, 100, 140)      25340     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 37, 50, 140)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 37, 50, 50)        63050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 18, 25, 50)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 18, 25, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22500)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               2880128   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 2,970,941\n",
      "Trainable params: 2,970,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3500 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "3500/3500 [==============================] - 658s 188ms/step - loss: 4.2945 - val_loss: 4.3309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2ee22fd5860>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# da provare\n",
    "X = encoded[\"pixels\"]\n",
    "y = pd.get_dummies(encoded[\"dx\"])\n",
    "#bag_class = ensemble()\n",
    "X = np.asarray(X.tolist())\n",
    "y = np.asarray(y)\n",
    "\n",
    "# splitting test and validation\n",
    "X_train, X_test1, y_train, y_test1 = train_test_split(X, y, test_size=0.30)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test1, y_test1, test_size=0.40)\n",
    "\n",
    "\n",
    "classifier = new_classifier3()\n",
    "classifier.fit(X_train, y_train, epochs=1, batch_size=100, shuffle=True, validation_data=(X_val, y_val)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 150, 200, 20)      1520      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 75, 100, 20)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 75, 100, 140)      25340     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 37, 50, 140)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 37, 50, 50)        63050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 18, 25, 50)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 18, 25, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 22500)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               2880128   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 2,970,941\n",
      "Trainable params: 2,970,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 0\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 121ms/step - loss: 0.4224\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 101ms/step - loss: 1.3660\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 103ms/step - loss: 0.5024\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 103ms/step - loss: 0.3957\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2957\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 106ms/step - loss: 0.7754\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 103ms/step - loss: 0.3998\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 103ms/step - loss: 0.3877\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 104ms/step - loss: 0.3502\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 103ms/step - loss: 0.3310\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 108ms/step - loss: 0.2893\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2926\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.3215\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2535\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 103ms/step - loss: 0.2468\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 103ms/step - loss: 0.2672\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 104ms/step - loss: 0.2827\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 104ms/step - loss: 0.3608\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2519\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2778\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.3178\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2066\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 101ms/step - loss: 0.3569\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 101ms/step - loss: 0.3312\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2473\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 103ms/step - loss: 0.2632\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2151\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 101ms/step - loss: 0.1855\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.4712\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.3340\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2865\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 101ms/step - loss: 0.2833\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 104ms/step - loss: 0.3148\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2144\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 101ms/step - loss: 0.2105\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-29a0025b4d82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mbatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mcl2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatches\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "cl2 = new_classifier3()\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "cl2.fit_generator(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(X_train) / 32, epochs=1)\n",
    "\n",
    "# here's a more \"manual\" example\n",
    "for e in range(2):\n",
    "    print('Epoch', e)\n",
    "    batches = 0\n",
    "    for x_batch, y_batch in datagen.flow(X_train, y_train, batch_size=20):\n",
    "        cl2.fit(x_batch, y_batch)\n",
    "        batches += 1\n",
    "        if batches >= len(X_train) / 20:\n",
    "            print('fine batch ', batches)\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
