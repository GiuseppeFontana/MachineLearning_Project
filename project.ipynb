{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creazione split\n",
    "#feat_train, feat_test, target_train, target_test = train_test_split(X, y, test_size=0.20, random_state=28) \n",
    "#smote = SMOTENC(sampling_strategy='dict', categorical_features=['bkl', 'vasc'])\n",
    "#X_sm, y_sm = smote.fit_sample(X,y)\n",
    "#len(X)\n",
    "#len(X_sm)\n",
    "\n",
    "\n",
    "#print(type(X))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##############################\n",
    "########## TODO ##############\n",
    "##############################\n",
    "- API che crea il dataframe contenente dx, nome img e pixel\n",
    "- scrivere il dataframe completo per ricaricarlo tutte le volte\n",
    "- scissione in X,y\n",
    "- data augmentation (tramite oversampling?)\n",
    "- ensamble o CNN? se ensemble, crearli stupidi e non complessi\n",
    "- provare il fit del bagging_class(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#import sklearn as skl\n",
    "import sklearn.preprocessing as preproc\n",
    "import numpy as np\n",
    "import keras as k\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#from time import time\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import tensorflow as tf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### variabili globali\n",
    "#### GIUSEPPE\n",
    "image_path = '..\\skin-cancer-mnist-ham10000\\HAM10000_images_part_1'\n",
    "#### FABIO\n",
    "# image_path = '..\\skin-cancer-mnist-ham10000\\HAM10000_images_part_1'\n",
    "csv_path = 'HAM10000_metadata.csv'\n",
    "dataset = pd.read_csv(csv_path, encoding = \"ISO-8859-1\")\n",
    "labels = set(dataset[\"dx\"])\n",
    "cat_column=[\"dx\"]\n",
    "ohe = preproc.OneHotEncoder(sparse=False, handle_unknown=\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## API varie\n",
    "# - carica in memoria immagini e label\n",
    "# - 1-hot encoding\n",
    "# - implementazione modello tramite ensamble (nel classificatore va incluso il numero di labels)\n",
    "# - train e test usando il bagging, ma prima bisogna fare SMOTE su vasc e bkl?\n",
    "\n",
    "\n",
    "\n",
    "# carica tutto in un nuovo dataframe\n",
    "def load_pictures(path, dataset):\n",
    "    col=[\"lesion_id\" ,\"image_id\",\"dx\",\"dx_type\" ,\"age\" ,\"sex\" ,\"localization\",\"path\",\"pixels\"]\n",
    "    dataset.insert(7,\"path\",None)\n",
    "    dataset.insert(8,\"pixels\",None)\n",
    "    data=pd.DataFrame(columns=col)\n",
    "    helper = pd.DataFrame(columns=col)\n",
    "    for _,_,files in os.walk(path+'\\\\'):\n",
    "        for file in files: \n",
    "            file_replace = file.replace(\".jpg\", \"\") #tagliare il .jpg che non compare nel dataset\n",
    "            path2=path+\"\\\\\"+file #path completo di un file\n",
    "            helper=dataset.loc[dataset[\"image_id\"]==file_replace] #tupla del file\n",
    "            helper[\"path\"]=path2\n",
    "            col=[\"lesion_id\" ,\"image_id\",\"dx\",\"dx_type\" ,\"age\" ,\"sex\" ,\"localization\"]\n",
    "            data = data.append(helper)\n",
    "    data[\"pixels\"]=data['path'].map(lambda x: np.asarray(Image.open(x).resize((200,150)))) #associazione ai pixel\n",
    "    return data\n",
    "\n",
    "\n",
    "def lab_encode(dataset):#Ho una sola colonna! \n",
    "    for col in cat_column:\n",
    "        new_le = preproc.LabelEncoder()\n",
    "        new_ds = dataset\n",
    "        new_ds[col] = new_le.fit_transform(dataset[col]) \n",
    "      #  label_encoders[col] = new_le \n",
    "    return new_ds\n",
    "\n",
    "def onehot_encode(dataset):\n",
    "    dataset_LabEncoded = lab_encode(dataset)\n",
    "    x=np.array([dataset_LabEncoded[\"dx\"]]) \n",
    "    y_onehot = ohe.fit_transform(x.reshape(-1,1))\n",
    "    return y_onehot\n",
    "\n",
    "\n",
    "# si prende tutto l'array di risultati\n",
    "def reverse_onehot(vector):\n",
    "    res = ohe.inverse_transform(vector)\n",
    "    return res\n",
    "\n",
    "\n",
    "# conteggio statistiche dataset\n",
    "def stats(dataset):\n",
    "    labels = set(dataset['dx'])\n",
    "    for label in labels:\n",
    "        print(str(label), ':\\t', str(dataset[dataset['dx']==label]['dx'].count()))\n",
    "        #print (label)\n",
    "\n",
    "        \n",
    "        \n",
    "def new_classifier():\n",
    "    input_img = Input(shape=(450, 600, 3))  # 3x600x450 image RGB \n",
    "    #print (tf.shape(input_img))\n",
    "    x = Conv2D(20, (5, 5), activation='relu', padding='same')(input_img) # 20x450x600\n",
    "    #print (tf.shape(x))\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x) # 20x225x300\n",
    "    #print (tf.shape(x))\n",
    "    x = Conv2D(140, (3, 3), activation='relu', padding='same')(x) # 140x75x100\n",
    "    #print (tf.shape(x))\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x) # 40x38x50\n",
    "    #print (tf.shape(x))\n",
    "    x = Conv2D(50, (3, 3), activation='relu', padding='same')(x) # 50x38x50\n",
    "    #print (tf.shape(x))\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x) # 50x19x25\n",
    "    #print (tf.shape(x))\n",
    "    x = Flatten()(x) # qui la x diventa monodimensionale\n",
    "    #print (tf.shape(x))\n",
    "    # da qualche parte ci va il numero delle label?\n",
    "    encoded = Dense(7, activation='softmax')(x)\n",
    "    classifier = k.models.Model(input_img, encoded)   #questo è il nostro base_estimator, compile configura per il training\n",
    "    classifier.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    return classifier\n",
    "\n",
    "def new_classifier2():\n",
    "    # Set the CNN model \n",
    "    input_shape = (450, 600, 3)\n",
    "    num_classes = 7\n",
    "    \n",
    "    model = k.models.Sequential()\n",
    "    model.add(Conv2D(20, kernel_size=(5, 5),activation='relu',padding = 'Same', input_shape = input_shape))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(140,kernel_size=(3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(50,kernel_size=(3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "def new_classifier3():\n",
    "    # Set the CNN model \n",
    "    input_shape = (150, 200, 3)\n",
    "    num_classes = 7\n",
    "    \n",
    "    model = k.models.Sequential()\n",
    "    model.add(Conv2D(20, kernel_size=(5, 5),activation='relu',padding = 'Same', input_shape = input_shape))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(140,kernel_size=(3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(50,kernel_size=(3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "def ensemble():\n",
    "    #da settare \n",
    "    #    base_estimator il classificatore come CNN,\n",
    "    #    n_estimators,\n",
    "    #    max_samples è il numero di elementi nei training set,\n",
    "    #    bootstrap se lo vogliamo o no (booleano),\n",
    "    #    n_jobs per il parallelismo,\n",
    "    classifier = new_classifier2()\n",
    "    bagging = BaggingClassifier(base_estimator=classifier, n_estimators=1, \n",
    "                                bootstrap=True, n_jobs=4)\n",
    "    return bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jph94\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#creazione dataframe\n",
    "ds = load_pictures(image_path, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding delle labels (dx)\n",
    "encoded = lab_encode(ds)\n",
    "encoded = encoded.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>2</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[187, 151, 192], [191, 155, 197], [192, 157,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>2</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[24, 13, 22], [24, 13, 23], [24, 14, 22], [2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>2</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[186, 127, 135], [189, 130, 138], [191, 136,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>2</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[23, 11, 16], [24, 11, 19], [24, 11, 19], [2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0027850</td>\n",
       "      <td>2</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[4, 0, 0], [4, 0, 1], [5, 1, 1], [7, 0, 2], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>HAM_0006180</td>\n",
       "      <td>ISIC_0028990</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[47, 22, 42], [52, 26, 46], [57, 31, 52], [6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>HAM_0004592</td>\n",
       "      <td>ISIC_0029141</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[151, 119, 129], [152, 121, 131], [152, 124,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>HAM_0005579</td>\n",
       "      <td>ISIC_0028393</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[126, 87, 71], [129, 90, 75], [132, 93, 78],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>HAM_0004034</td>\n",
       "      <td>ISIC_0024948</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[203, 154, 155], [204, 154, 154], [205, 151,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td>HAM_0001565</td>\n",
       "      <td>ISIC_0028619</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[32, 16, 20], [31, 14, 20], [31, 14, 19], [2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lesion_id      image_id  dx dx_type   age     sex     localization  \\\n",
       "0      HAM_0000118  ISIC_0027419   2   histo  80.0    male            scalp   \n",
       "1      HAM_0000118  ISIC_0025030   2   histo  80.0    male            scalp   \n",
       "2      HAM_0002730  ISIC_0026769   2   histo  80.0    male            scalp   \n",
       "3      HAM_0002730  ISIC_0025661   2   histo  80.0    male            scalp   \n",
       "5      HAM_0001466  ISIC_0027850   2   histo  75.0    male              ear   \n",
       "...            ...           ...  ..     ...   ...     ...              ...   \n",
       "9997   HAM_0006180  ISIC_0028990   0   histo  70.0    male  upper extremity   \n",
       "10003  HAM_0004592  ISIC_0029141   0   histo  60.0  female             face   \n",
       "10005  HAM_0005579  ISIC_0028393   0   histo  80.0    male             face   \n",
       "10006  HAM_0004034  ISIC_0024948   0   histo  55.0  female             face   \n",
       "10007  HAM_0001565  ISIC_0028619   0   histo  60.0  female             face   \n",
       "\n",
       "                                                    path  \\\n",
       "0      ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "1      ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "2      ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "3      ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "5      ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "...                                                  ...   \n",
       "9997   ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "10003  ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "10005  ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "10006  ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "10007  ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "\n",
       "                                                  pixels  \n",
       "0      [[[187, 151, 192], [191, 155, 197], [192, 157,...  \n",
       "1      [[[24, 13, 22], [24, 13, 23], [24, 14, 22], [2...  \n",
       "2      [[[186, 127, 135], [189, 130, 138], [191, 136,...  \n",
       "3      [[[23, 11, 16], [24, 11, 19], [24, 11, 19], [2...  \n",
       "5      [[[4, 0, 0], [4, 0, 1], [5, 1, 1], [7, 0, 2], ...  \n",
       "...                                                  ...  \n",
       "9997   [[[47, 22, 42], [52, 26, 46], [57, 31, 52], [6...  \n",
       "10003  [[[151, 119, 129], [152, 121, 131], [152, 124,...  \n",
       "10005  [[[126, 87, 71], [129, 90, 75], [132, 93, 78],...  \n",
       "10006  [[[203, 154, 155], [204, 154, 154], [205, 151,...  \n",
       "10007  [[[32, 16, 20], [31, 14, 20], [31, 14, 19], [2...  \n",
       "\n",
       "[5000 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# da provare\n",
    "#X = encoded[\"pixels\"]\n",
    "#y = encoded[\"dx\"]\n",
    "#bag_class = ensemble()\n",
    "#X = np.asarray(X)\n",
    "#y = np.asarray(y)\n",
    "#\n",
    "#dataset_size = len(X)\n",
    "#reshaped = np.reshape(X,(dataset_size,-1))\n",
    "#params = bag_class.get_params()\n",
    "#bag_class.fit(reshaped, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 150, 200, 20)      1520      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 75, 100, 20)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 75, 100, 140)      25340     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 37, 50, 140)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 37, 50, 50)        63050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 18, 25, 50)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 18, 25, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22500)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               2880128   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 2,970,941\n",
      "Trainable params: 2,970,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3500 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "3500/3500 [==============================] - 658s 188ms/step - loss: 4.2945 - val_loss: 4.3309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2ee22fd5860>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# da provare\n",
    "X = encoded[\"pixels\"]\n",
    "y = pd.get_dummies(encoded[\"dx\"])\n",
    "#bag_class = ensemble()\n",
    "X = np.asarray(X.tolist())\n",
    "y = np.asarray(y)\n",
    "\n",
    "# splitting test and validation\n",
    "X_train, X_test1, y_train, y_test1 = train_test_split(X, y, test_size=0.30)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test1, y_test1, test_size=0.40)\n",
    "\n",
    "\n",
    "classifier = new_classifier3()\n",
    "classifier.fit(X_train, y_train, epochs=1, batch_size=100, shuffle=True, validation_data=(X_val, y_val)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(encoded[\"dx\"])\n",
    "y = np.asarray(y)\n",
    "\n",
    "y[0]\n",
    "#X[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
