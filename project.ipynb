{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn as skl\n",
    "import sklearn.preprocessing as preproc\n",
    "import numpy as np\n",
    "import keras as k\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Flatten, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from time import time\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### variabili globali\n",
    "image_path = '..\\..\\skin-cancer-mnist-ham10000\\HAM10000_images_part_1'\n",
    "csv_path = 'HAM10000_metadata.csv'\n",
    "dataset = pd.read_csv(csv_path, encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## API varie\n",
    "\n",
    "# - carica in memoria immagini e label\n",
    "# - train e test usando il bagging\n",
    "# - implementazione modello tramite ensamble\n",
    "\n",
    "\n",
    "# carica le immagini e le label\n",
    "def loadPictures(path, dataset):\n",
    "    X=[];\n",
    "    y=[];\n",
    "    \n",
    "    for _,_,files in os.walk(path+\"/\"):\n",
    "        for file in files: \n",
    "            #print(file) \n",
    "            #if file.find('.jpg')<0:\n",
    "            #    continue     \n",
    "            img = cv2.imread(path+\"/\"+file)\n",
    "            X.append(img)\n",
    "            file = file.replace(\".jpg\", \"\") #tagliare il .jpg che non compare nel dataset\n",
    "            y.append(dataset[dataset['image_id'] == file]['dx'])\n",
    "            \n",
    "    #conteggio label (serve per l'ultimo livello delle CNN)    \n",
    "    labels = set(dataset['dx'])\n",
    "    return X,y,labels\n",
    "\n",
    "\n",
    "\n",
    "# conteggio statistiche dataset\n",
    "def stats(dataset):\n",
    "    labels = set(dataset['dx'])\n",
    "    for label in labels:\n",
    "        print(label, ': ', dataset[dataset['dx']==label]['dx'].count())\n",
    "        #print (label)\n",
    "# ensamble\n",
    "\n",
    "\n",
    "#input_img = Input(shape=(199, 199, 1))  # 1x199x199 image con 1 canale solo (grigio) \n",
    "#    x = Conv2D(16, (5, 5), activation='relu', padding='same')(input_img) # 16x199x199\n",
    "#    x = MaxPooling2D((2, 2), padding='same')(x) # 16x100x100\n",
    "#    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x) # 8x100x100\n",
    "#    x = MaxPooling2D((2, 2), padding='same')(x) # 8x50x50\n",
    "#    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x) # 8x50x50\n",
    "#    x = MaxPooling2D((2, 2), padding='same')(x) # 8x25x25\n",
    "#    x = Flatten()(x)\n",
    "#    encoded = Dense(16, activation='softmax')(x)\n",
    "#    \n",
    "#    classifier = k.models.Model(input_img, encoded)   #questo è il nostro base_estimator, se compile non è importante\n",
    "#    classifier.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "def ensemble():\n",
    "    #da settare \n",
    "    #    base_estimator il classificatore come CNN,\n",
    "    #    n_estimators,\n",
    "    #    max_samples è il numero di elementi nei training set,\n",
    "    #    bootstrap se lo vogliamo o no (booleano),\n",
    "    #    n_jobs per il parallelismo,\n",
    "    bagging = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5)\n",
    "    return bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,labels = loadPictures(image_path, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'categorical_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-7290761508bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#creazione split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#feat_train, feat_test, target_train, target_test = train_test_split(X, y, test_size=0.20, random_state=28)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msmote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTENC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX_sm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_sm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'categorical_features'"
     ]
    }
   ],
   "source": [
    "#creazione split\n",
    "#feat_train, feat_test, target_train, target_test = train_test_split(X, y, test_size=0.20, random_state=28) \n",
    "smote = SMOTENC(sampling_strategy='dict', cathegorical_features=)\n",
    "X_sm, y_sm = smote.fit_sample(X,y)\n",
    "len(X)\n",
    "len(X_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
