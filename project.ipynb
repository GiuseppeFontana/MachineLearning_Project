{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creazione split\n",
    "#feat_train, feat_test, target_train, target_test = train_test_split(X, y, test_size=0.20, random_state=28) \n",
    "#smote = SMOTENC(sampling_strategy='dict', categorical_features=['bkl', 'vasc'])\n",
    "#X_sm, y_sm = smote.fit_sample(X,y)\n",
    "#len(X)\n",
    "#len(X_sm)\n",
    "\n",
    "\n",
    "#print(type(X))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##############################\n",
    "########## TODO ##############\n",
    "##############################\n",
    "- API che crea il dataframe contenente dx, nome img e pixel\n",
    "- scrivere il dataframe completo per ricaricarlo tutte le volte\n",
    "- scissione in X,y\n",
    "- data augmentation (tramite oversampling?)\n",
    "- ensamble o CNN? se ensemble, crearli stupidi e non complessi\n",
    "- provare il fit del bagging_class(?)\n",
    "\n",
    "\n",
    "os.replace(\"path/to/current/file.foo\", \"path/to/new/destination/for/file.foo\")\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Fit the model\n",
    "epochs = 50 \n",
    "batch_size = 10\n",
    "history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (x_validate,y_validate),\n",
    "                              verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])\n",
    "\n",
    "batch():\n",
    "    carico l'insieme di immagini\n",
    "    generator di varianti\n",
    "    fit\n",
    "    chiudo le immagini\n",
    "    pulisco memoria delle varianti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#import sklearn as skl\n",
    "import sklearn.preprocessing as preproc\n",
    "import numpy as np\n",
    "import keras as k\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#from time import time\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### variabili globali\n",
    "#### GIUSEPPE\n",
    "image_path = '..\\skin-cancer-mnist-ham10000\\HAM10000_images_part_1'\n",
    "#### FABIO\n",
    "# image_path = '..\\skin-cancer-mnist-ham10000\\HAM10000_images_part_1'\n",
    "csv_path = 'HAM10000_metadata.csv'\n",
    "dataset = pd.read_csv(csv_path, encoding = \"ISO-8859-1\")\n",
    "labels = set(dataset[\"dx\"])\n",
    "cat_column=[\"dx\"]\n",
    "#ohe = preproc.OneHotEncoder(sparse=False, handle_unknown=\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## API varie\n",
    "# - carica in memoria immagini e label\n",
    "# - 1-hot encoding\n",
    "# - implementazione modello tramite ensamble (nel classificatore va incluso il numero di labels)\n",
    "# - train e test usando il bagging, ma prima bisogna fare SMOTE su vasc e bkl?\n",
    "\n",
    "\n",
    "\n",
    "# carica tutto in un nuovo dataframe\n",
    "def load_pictures(path, dataset):\n",
    "    col=[\"lesion_id\" ,\"image_id\",\"dx\",\"dx_type\" ,\"age\" ,\"sex\" ,\"localization\",\"path\",\"pixels\"]\n",
    "    dataset.insert(7,\"path\",None)\n",
    "    dataset.insert(8,\"pixels\",None)\n",
    "    data=pd.DataFrame(columns=col)\n",
    "    helper = pd.DataFrame(columns=col)\n",
    "    for _,_,files in os.walk(path+'\\\\'):\n",
    "        for file in files: \n",
    "            file_replace = file.replace(\".jpg\", \"\") #tagliare il .jpg che non compare nel dataset\n",
    "            path2=path+\"\\\\\"+file #path completo di un file\n",
    "            helper=dataset.loc[dataset[\"image_id\"]==file_replace] #tupla del file\n",
    "            helper[\"path\"]=path2\n",
    "            col=[\"lesion_id\" ,\"image_id\",\"dx\",\"dx_type\" ,\"age\" ,\"sex\" ,\"localization\"]\n",
    "            data = data.append(helper)\n",
    "    data[\"pixels\"]=data['path'].map(lambda x: np.asarray(Image.open(x).resize((200,150)))) #associazione ai pixel\n",
    "    return data\n",
    "\n",
    "\n",
    "def lab_encode(dataset):#Ho una sola colonna! \n",
    "    for col in cat_column:\n",
    "        new_le = preproc.LabelEncoder()\n",
    "        new_ds = dataset\n",
    "        new_ds[col] = new_le.fit_transform(dataset[col]) \n",
    "      #  label_encoders[col] = new_le \n",
    "    return new_ds\n",
    "\n",
    "def onehot_encode(dataset):\n",
    "    dataset_LabEncoded = lab_encode(dataset)\n",
    "    x=np.array([dataset_LabEncoded[\"dx\"]]) \n",
    "    y_onehot = ohe.fit_transform(x.reshape(-1,1))\n",
    "    return y_onehot\n",
    "\n",
    "\n",
    "# si prende tutto l'array di risultati\n",
    "def reverse_onehot(vector):\n",
    "    res = ohe.inverse_transform(vector)\n",
    "    return res\n",
    "\n",
    "\n",
    "# conteggio statistiche dataset\n",
    "def stats(dataset):\n",
    "    labels = set(dataset['dx'])\n",
    "    for label in labels:\n",
    "        print(str(label), ':\\t', str(dataset[dataset['dx']==label]['dx'].count()))\n",
    "        #print (label)\n",
    "\n",
    "        \n",
    "        \n",
    "def new_classifier():\n",
    "    input_img = Input(shape=(450, 600, 3))  # 3x600x450 image RGB \n",
    "    #print (tf.shape(input_img))\n",
    "    x = Conv2D(20, (5, 5), activation='relu', padding='same')(input_img) # 20x450x600\n",
    "    #print (tf.shape(x))\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x) # 20x225x300\n",
    "    #print (tf.shape(x))\n",
    "    x = Conv2D(140, (3, 3), activation='relu', padding='same')(x) # 140x75x100\n",
    "    #print (tf.shape(x))\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x) # 40x38x50\n",
    "    #print (tf.shape(x))\n",
    "    x = Conv2D(50, (3, 3), activation='relu', padding='same')(x) # 50x38x50\n",
    "    #print (tf.shape(x))\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x) # 50x19x25\n",
    "    #print (tf.shape(x))\n",
    "    x = Flatten()(x) # qui la x diventa monodimensionale\n",
    "    #print (tf.shape(x))\n",
    "    # da qualche parte ci va il numero delle label?\n",
    "    encoded = Dense(7, activation='softmax')(x)\n",
    "    classifier = k.models.Model(input_img, encoded)   #questo Ã¨ il nostro base_estimator, compile configura per il training\n",
    "    classifier.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    return classifier\n",
    "\n",
    "def new_classifier2():\n",
    "    # Set the CNN model \n",
    "    input_shape = (450, 600, 3)\n",
    "    num_classes = 7\n",
    "    \n",
    "    model = k.models.Sequential()\n",
    "    model.add(Conv2D(20, kernel_size=(5, 5),activation='relu',padding = 'Same', input_shape = input_shape))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(140,kernel_size=(3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(50,kernel_size=(3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "def new_classifier3():\n",
    "    # Set the CNN model \n",
    "    input_shape = (150, 200, 3)\n",
    "    num_classes = 7\n",
    "    \n",
    "    model = k.models.Sequential()\n",
    "    model.add(Conv2D(20, kernel_size=(5, 5),activation='relu',padding = 'Same', input_shape = input_shape))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(140,kernel_size=(3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(50,kernel_size=(3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "def ensemble():\n",
    "    #da settare \n",
    "    #    base_estimator il classificatore come CNN,\n",
    "    #    n_estimators,\n",
    "    #    max_samples Ã¨ il numero di elementi nei training set,\n",
    "    #    bootstrap se lo vogliamo o no (booleano),\n",
    "    #    n_jobs per il parallelismo,\n",
    "    classifier = new_classifier2()\n",
    "    bagging = BaggingClassifier(base_estimator=classifier, n_estimators=1, \n",
    "                                bootstrap=True, n_jobs=4)\n",
    "    return bagging\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jph94\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#creazione dataframe\n",
    "ds = load_pictures(image_path, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding delle labels (dx)\n",
    "encoded = lab_encode(ds)\n",
    "encoded = encoded.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>2</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[187, 151, 192], [191, 155, 197], [192, 157,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>2</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[24, 13, 22], [24, 13, 23], [24, 14, 22], [2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>2</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[186, 127, 135], [189, 130, 138], [191, 136,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>2</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[23, 11, 16], [24, 11, 19], [24, 11, 19], [2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0027850</td>\n",
       "      <td>2</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[4, 0, 0], [4, 0, 1], [5, 1, 1], [7, 0, 2], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>HAM_0006180</td>\n",
       "      <td>ISIC_0028990</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[47, 22, 42], [52, 26, 46], [57, 31, 52], [6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>HAM_0004592</td>\n",
       "      <td>ISIC_0029141</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[151, 119, 129], [152, 121, 131], [152, 124,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>HAM_0005579</td>\n",
       "      <td>ISIC_0028393</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[126, 87, 71], [129, 90, 75], [132, 93, 78],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>HAM_0004034</td>\n",
       "      <td>ISIC_0024948</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[203, 154, 155], [204, 154, 154], [205, 151,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td>HAM_0001565</td>\n",
       "      <td>ISIC_0028619</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>..\\skin-cancer-mnist-ham10000\\HAM10000_images_...</td>\n",
       "      <td>[[[32, 16, 20], [31, 14, 20], [31, 14, 19], [2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lesion_id      image_id  dx dx_type   age     sex     localization  \\\n",
       "0      HAM_0000118  ISIC_0027419   2   histo  80.0    male            scalp   \n",
       "1      HAM_0000118  ISIC_0025030   2   histo  80.0    male            scalp   \n",
       "2      HAM_0002730  ISIC_0026769   2   histo  80.0    male            scalp   \n",
       "3      HAM_0002730  ISIC_0025661   2   histo  80.0    male            scalp   \n",
       "5      HAM_0001466  ISIC_0027850   2   histo  75.0    male              ear   \n",
       "...            ...           ...  ..     ...   ...     ...              ...   \n",
       "9997   HAM_0006180  ISIC_0028990   0   histo  70.0    male  upper extremity   \n",
       "10003  HAM_0004592  ISIC_0029141   0   histo  60.0  female             face   \n",
       "10005  HAM_0005579  ISIC_0028393   0   histo  80.0    male             face   \n",
       "10006  HAM_0004034  ISIC_0024948   0   histo  55.0  female             face   \n",
       "10007  HAM_0001565  ISIC_0028619   0   histo  60.0  female             face   \n",
       "\n",
       "                                                    path  \\\n",
       "0      ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "1      ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "2      ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "3      ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "5      ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "...                                                  ...   \n",
       "9997   ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "10003  ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "10005  ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "10006  ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "10007  ..\\skin-cancer-mnist-ham10000\\HAM10000_images_...   \n",
       "\n",
       "                                                  pixels  \n",
       "0      [[[187, 151, 192], [191, 155, 197], [192, 157,...  \n",
       "1      [[[24, 13, 22], [24, 13, 23], [24, 14, 22], [2...  \n",
       "2      [[[186, 127, 135], [189, 130, 138], [191, 136,...  \n",
       "3      [[[23, 11, 16], [24, 11, 19], [24, 11, 19], [2...  \n",
       "5      [[[4, 0, 0], [4, 0, 1], [5, 1, 1], [7, 0, 2], ...  \n",
       "...                                                  ...  \n",
       "9997   [[[47, 22, 42], [52, 26, 46], [57, 31, 52], [6...  \n",
       "10003  [[[151, 119, 129], [152, 121, 131], [152, 124,...  \n",
       "10005  [[[126, 87, 71], [129, 90, 75], [132, 93, 78],...  \n",
       "10006  [[[203, 154, 155], [204, 154, 154], [205, 151,...  \n",
       "10007  [[[32, 16, 20], [31, 14, 20], [31, 14, 19], [2...  \n",
       "\n",
       "[5000 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# da provare\n",
    "#X = encoded[\"pixels\"]\n",
    "#y = encoded[\"dx\"]\n",
    "#bag_class = ensemble()\n",
    "#X = np.asarray(X)\n",
    "#y = np.asarray(y)\n",
    "#\n",
    "#dataset_size = len(X)\n",
    "#reshaped = np.reshape(X,(dataset_size,-1))\n",
    "#params = bag_class.get_params()\n",
    "#bag_class.fit(reshaped, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 150, 200, 20)      1520      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 75, 100, 20)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 75, 100, 140)      25340     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 37, 50, 140)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 37, 50, 50)        63050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 18, 25, 50)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 18, 25, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22500)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               2880128   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 2,970,941\n",
      "Trainable params: 2,970,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3500 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "3500/3500 [==============================] - 658s 188ms/step - loss: 4.2945 - val_loss: 4.3309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2ee22fd5860>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# da provare\n",
    "X = encoded[\"pixels\"]\n",
    "y = pd.get_dummies(encoded[\"dx\"])\n",
    "#bag_class = ensemble()\n",
    "X = np.asarray(X.tolist())\n",
    "y = np.asarray(y)\n",
    "\n",
    "# splitting test and validation\n",
    "X_train, X_test1, y_train, y_test1 = train_test_split(X, y, test_size=0.30)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test1, y_test1, test_size=0.40)\n",
    "\n",
    "\n",
    "classifier = new_classifier3()\n",
    "classifier.fit(X_train, y_train, epochs=1, batch_size=100, shuffle=True, validation_data=(X_val, y_val)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(encoded[\"dx\"])\n",
    "y = np.asarray(y)\n",
    "\n",
    "y[0]\n",
    "#X[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 150, 200, 20)      1520      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 75, 100, 20)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 75, 100, 140)      25340     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 37, 50, 140)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 37, 50, 50)        63050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 18, 25, 50)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 18, 25, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 22500)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               2880128   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 2,970,941\n",
      "Trainable params: 2,970,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 0\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 121ms/step - loss: 0.4224\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 101ms/step - loss: 1.3660\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 103ms/step - loss: 0.5024\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 103ms/step - loss: 0.3957\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2957\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 106ms/step - loss: 0.7754\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 103ms/step - loss: 0.3998\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 103ms/step - loss: 0.3877\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 104ms/step - loss: 0.3502\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 103ms/step - loss: 0.3310\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 108ms/step - loss: 0.2893\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2926\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.3215\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2535\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 103ms/step - loss: 0.2468\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 103ms/step - loss: 0.2672\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 104ms/step - loss: 0.2827\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 104ms/step - loss: 0.3608\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2519\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2778\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.3178\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2066\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 101ms/step - loss: 0.3569\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 101ms/step - loss: 0.3312\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2473\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 103ms/step - loss: 0.2632\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2151\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 101ms/step - loss: 0.1855\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.4712\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.3340\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2865\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 101ms/step - loss: 0.2833\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 104ms/step - loss: 0.3148\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2144\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 2s 101ms/step - loss: 0.2105\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-29a0025b4d82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mbatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mcl2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatches\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "cl2 = new_classifier3()\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "cl2.fit_generator(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(X_train) / 32, epochs=1)\n",
    "\n",
    "# here's a more \"manual\" example\n",
    "for e in range(2):\n",
    "    print('Epoch', e)\n",
    "    batches = 0\n",
    "    for x_batch, y_batch in datagen.flow(X_train, y_train, batch_size=20):\n",
    "        cl2.fit(x_batch, y_batch)\n",
    "        batches += 1\n",
    "        if batches >= len(X_train) / 20:\n",
    "            print('fine batch ', batches)\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
