{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "6zfQmfZgx7wd",
    "outputId": "4976f610-1235-4383-8fbb-be706be26d8f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import sklearn.preprocessing as preproc\n",
    "import numpy as np\n",
    "import keras as k\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "from keras.models import Sequential\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#from time import time\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import BatchNormalization\n",
    "import math\n",
    "import shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from google.colab import drive\n",
    "from keras.callbacks import History \n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "QP9TYLIVydGv",
    "outputId": "b032d7cf-8f00-41bf-dd4c-e6a702551adc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n",
      "/gdrive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/gdrive')\n",
    "%cd /gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SnOeUe6lyiTF"
   },
   "outputs": [],
   "source": [
    "!mkdir /csv\n",
    "!cp /gdrive/My\\ Drive/MachineLearning/dataframe_completo_2.csv /csv\n",
    "!cp /gdrive/My\\ Drive/MachineLearning/dataframe_originale.csv /csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sfGJzBFwykVg"
   },
   "outputs": [],
   "source": [
    "#### variabili globali\n",
    "csv_completo_2 = '/csv/dataframe_completo_2.csv' \n",
    "csv_orig = '/csv/dataframe_originale.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GynPff0rzaSw"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(csv_completo_2, encoding = \"ISO-8859-1\")\n",
    "originale = pd.read_csv(csv_orig, encoding = \"ISO-8859-1\")\n",
    "\n",
    "#  ritorna la parte di dataset che nel nome contiene il nome delle tuple di originale \n",
    "# (usato solo dopo aver partizionato originale)\n",
    "def estendi(dataset, originale):\n",
    "  res = pd.DataFrame()\n",
    "  for index2 in range(len(originale)):\n",
    "    temp = dataset[dataset[\"image_id\"].str.contains(originale.iloc[index2][\"image_id\"])]\n",
    "    res = res.append(temp)\n",
    "    if index2 % 1000 == 0:\n",
    "      print(index2)\n",
    "  return res\n",
    "\n",
    "# ritorna le 2 partizioni del dataframe (che non deve essere esteso) di fattori factor e 1-factor\n",
    "# es. factor = 0.8\n",
    "def partiziona(dataframe, factor):\n",
    "  part1 = pd.DataFrame()  # factor originali\n",
    "  part2 = pd.DataFrame()  # (1-factor) originali\n",
    "  for elem in range(7):\n",
    "    n = dataframe[dataframe['dx']==elem]['dx'].count() \n",
    "    p8 = int(n*factor)\n",
    "    print(\"n di tipo \", elem, \":\\t\", n, \"\\tandranno in part1:\\t\", p8)\n",
    "\n",
    "    blocco = dataframe[dataframe['dx']==elem]\n",
    "    blocco1 = blocco.sample(n=p8)\n",
    "    part1 = part1.append(blocco1)\n",
    "    part2 = part2.append(blocco.drop(blocco1.index))\n",
    "\n",
    "  print(\"size part1: \", len(part1))\n",
    "  print(\"size part2: \", len(part2))\n",
    "\n",
    "  return part1, part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "7PTKQTYEHgko",
    "outputId": "146ff072-51ae-4971-98c9-d6b6c29a13da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n di tipo  0 :\t 327 \tandranno in part1:\t 261\n",
      "n di tipo  1 :\t 514 \tandranno in part1:\t 411\n",
      "n di tipo  2 :\t 1099 \tandranno in part1:\t 879\n",
      "n di tipo  3 :\t 115 \tandranno in part1:\t 92\n",
      "n di tipo  4 :\t 1113 \tandranno in part1:\t 890\n",
      "n di tipo  5 :\t 6705 \tandranno in part1:\t 5364\n",
      "n di tipo  6 :\t 142 \tandranno in part1:\t 113\n",
      "size part1:  8010\n",
      "size part2:  2005\n"
     ]
    }
   ],
   "source": [
    "# split di \"originale\" 80 20 (il 20 sarà il test)\n",
    "orig_08, orig_02 = partiziona(originale, 0.8)\n",
    "\n",
    "orig_08.to_csv('/csv/orig_08.csv', index=False)\n",
    "orig_02.to_csv('/csv/orig_02.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "aPUD4vEE8L08",
    "outputId": "e25aa51d-d1ba-4eaf-8596-fecdea03d937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n di tipo  0 :\t 261 \tandranno in part1:\t 208\n",
      "n di tipo  1 :\t 411 \tandranno in part1:\t 328\n",
      "n di tipo  2 :\t 879 \tandranno in part1:\t 703\n",
      "n di tipo  3 :\t 92 \tandranno in part1:\t 73\n",
      "n di tipo  4 :\t 890 \tandranno in part1:\t 712\n",
      "n di tipo  5 :\t 5364 \tandranno in part1:\t 4291\n",
      "n di tipo  6 :\t 113 \tandranno in part1:\t 90\n",
      "size part1:  6405\n",
      "size part2:  1605\n"
     ]
    }
   ],
   "source": [
    "# split di \"orig_08\" 80 20 (80 train 20 validation)\n",
    "orig_064, orig_016 = partiziona(orig_08, 0.8)\n",
    "\n",
    "orig_064.to_csv('/csv/orig_064.csv', index=False)\n",
    "orig_016.to_csv('/csv/orig_016.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "d-4nN1zYz4C-",
    "outputId": "e5b3a88a-052e-4c17-87e2-58de905dd276"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "# dalla partizione del datset originale (orig_X) faccio la partizione del dataset esteso (esteso_X)\n",
    "#esteso_02 = estendi(dataset, orig_02)\n",
    "esteso_064 = estendi(dataset, orig_064)\n",
    "#esteso_016 = estendi(dataset, orig_016)\n",
    "\n",
    "#print(\"esteso:\\t\", len(dataset), \"\\ntrain:\\t\", len(esteso_064), \"\\nvalidation:\\t\", len(esteso_016), \"\\ntest:\\t\", len(esteso_02))\n",
    "\n",
    "#esteso_02.to_csv('/csv/esteso_02.csv', index=False)\n",
    "esteso_064.to_csv('/csv/esteso_064.csv', index=False)\n",
    "#esteso_016.to_csv('/csv/esteso_016.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQ7TxD-XNoSq"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('/csv/orig_016.csv')\n",
    "files.download('/csv/orig_02.csv',)\n",
    "files.download('/csv/esteso_064.csv',)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nuovi dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
