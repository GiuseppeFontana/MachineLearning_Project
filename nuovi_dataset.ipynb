{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nuovi dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zfQmfZgx7wd",
        "colab_type": "code",
        "outputId": "4976f610-1235-4383-8fbb-be706be26d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# imports\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "#import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn\n",
        "import sklearn.preprocessing as preproc\n",
        "import numpy as np\n",
        "import keras as k\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Flatten, Dense, Dropout, MaxPool2D\n",
        "from keras.models import Sequential\n",
        "#import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "#from time import time\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import BatchNormalization\n",
        "import math\n",
        "import shutil\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from google.colab import drive\n",
        "from keras.callbacks import History \n",
        "from keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP9TYLIVydGv",
        "colab_type": "code",
        "outputId": "b032d7cf-8f00-41bf-dd4c-e6a702551adc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnOeUe6lyiTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /csv\n",
        "!cp /gdrive/My\\ Drive/MachineLearning/dataframe_completo_2.csv /csv\n",
        "!cp /gdrive/My\\ Drive/MachineLearning/dataframe_originale.csv /csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfGJzBFwykVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### variabili globali\n",
        "csv_completo_2 = '/csv/dataframe_completo_2.csv' \n",
        "csv_orig = '/csv/dataframe_originale.csv' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GynPff0rzaSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv(csv_completo_2, encoding = \"ISO-8859-1\")\n",
        "originale = pd.read_csv(csv_orig, encoding = \"ISO-8859-1\")\n",
        "\n",
        "#  ritorna la parte di dataset che nel nome contiene il nome delle tuple di originale \n",
        "# (usato solo dopo aver partizionato originale)\n",
        "def estendi(dataset, originale):\n",
        "  res = pd.DataFrame()\n",
        "  for index2 in range(len(originale)):\n",
        "    temp = dataset[dataset[\"image_id\"].str.contains(originale.iloc[index2][\"image_id\"])]\n",
        "    res = res.append(temp)\n",
        "    if index2 % 1000 == 0:\n",
        "      print(index2)\n",
        "  return res\n",
        "\n",
        "# ritorna le 2 partizioni del dataframe (che non deve essere esteso) di fattori factor e 1-factor\n",
        "# es. factor = 0.8\n",
        "def partiziona(dataframe, factor):\n",
        "  part1 = pd.DataFrame()  # factor originali\n",
        "  part2 = pd.DataFrame()  # (1-factor) originali\n",
        "  for elem in range(7):\n",
        "    n = dataframe[dataframe['dx']==elem]['dx'].count() \n",
        "    p8 = int(n*factor)\n",
        "    print(\"n di tipo \", elem, \":\\t\", n, \"\\tandranno in part1:\\t\", p8)\n",
        "\n",
        "    blocco = dataframe[dataframe['dx']==elem]\n",
        "    blocco1 = blocco.sample(n=p8)\n",
        "    part1 = part1.append(blocco1)\n",
        "    part2 = part2.append(blocco.drop(blocco1.index))\n",
        "\n",
        "  print(\"size part1: \", len(part1))\n",
        "  print(\"size part2: \", len(part2))\n",
        "\n",
        "  return part1, part2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PTKQTYEHgko",
        "colab_type": "code",
        "outputId": "146ff072-51ae-4971-98c9-d6b6c29a13da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# split di \"originale\" 80 20 (il 20 sarà il test)\n",
        "orig_08, orig_02 = partiziona(originale, 0.8)\n",
        "\n",
        "orig_08.to_csv('/csv/orig_08.csv', index=False)\n",
        "orig_02.to_csv('/csv/orig_02.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n di tipo  0 :\t 327 \tandranno in part1:\t 261\n",
            "n di tipo  1 :\t 514 \tandranno in part1:\t 411\n",
            "n di tipo  2 :\t 1099 \tandranno in part1:\t 879\n",
            "n di tipo  3 :\t 115 \tandranno in part1:\t 92\n",
            "n di tipo  4 :\t 1113 \tandranno in part1:\t 890\n",
            "n di tipo  5 :\t 6705 \tandranno in part1:\t 5364\n",
            "n di tipo  6 :\t 142 \tandranno in part1:\t 113\n",
            "size part1:  8010\n",
            "size part2:  2005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPUD4vEE8L08",
        "colab_type": "code",
        "outputId": "e25aa51d-d1ba-4eaf-8596-fecdea03d937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# split di \"orig_08\" 80 20 (80 train 20 validation)\n",
        "orig_064, orig_016 = partiziona(orig_08, 0.8)\n",
        "\n",
        "orig_064.to_csv('/csv/orig_064.csv', index=False)\n",
        "orig_016.to_csv('/csv/orig_016.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n di tipo  0 :\t 261 \tandranno in part1:\t 208\n",
            "n di tipo  1 :\t 411 \tandranno in part1:\t 328\n",
            "n di tipo  2 :\t 879 \tandranno in part1:\t 703\n",
            "n di tipo  3 :\t 92 \tandranno in part1:\t 73\n",
            "n di tipo  4 :\t 890 \tandranno in part1:\t 712\n",
            "n di tipo  5 :\t 5364 \tandranno in part1:\t 4291\n",
            "n di tipo  6 :\t 113 \tandranno in part1:\t 90\n",
            "size part1:  6405\n",
            "size part2:  1605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-4nN1zYz4C-",
        "colab_type": "code",
        "outputId": "e5b3a88a-052e-4c17-87e2-58de905dd276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# dalla partizione del datset originale (orig_X) faccio la partizione del dataset esteso (esteso_X)\n",
        "#esteso_02 = estendi(dataset, orig_02)\n",
        "esteso_064 = estendi(dataset, orig_064)\n",
        "#esteso_016 = estendi(dataset, orig_016)\n",
        "\n",
        "#print(\"esteso:\\t\", len(dataset), \"\\ntrain:\\t\", len(esteso_064), \"\\nvalidation:\\t\", len(esteso_016), \"\\ntest:\\t\", len(esteso_02))\n",
        "\n",
        "#esteso_02.to_csv('/csv/esteso_02.csv', index=False)\n",
        "esteso_064.to_csv('/csv/esteso_064.csv', index=False)\n",
        "#esteso_016.to_csv('/csv/esteso_016.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ7TxD-XNoSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/csv/orig_016.csv')\n",
        "files.download('/csv/orig_02.csv',)\n",
        "files.download('/csv/esteso_064.csv',)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}