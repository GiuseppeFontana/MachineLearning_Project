{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- analisi dataset\n",
    "    - analisi features\n",
    "        - print della correlazione tra le features e le label            (DAFARE)\n",
    "        - scelta delle sole immagini e scarto delle features nel csv\n",
    "    - analisi immagini\n",
    "        - stats() nel dataset\n",
    "        - (opzionale?) print istogrammi delle label                      (DAFARE)\n",
    "- pre-processing\n",
    "    - data augmentation\n",
    "        - obiettivo di 6000 immagini per label\n",
    "        - arricchimento dataframe\n",
    "    - image rescaling (600x450 => 200x150)\n",
    "        - (opzionale?) motivi del rescaling\n",
    "    - split in train/test/validation\n",
    "        - sta su \"nuovi dataset\" in google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import cv2\n",
    "import sklearn.preprocessing as preproc\n",
    "import numpy as np\n",
    "import keras as k\n",
    "#import matplotlib.pyplot as plt\n",
    "#from time import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import math\n",
    "import shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dichiarazione funzioni\n",
    "\n",
    "# codifica la colonna dx da originale (stringhe) a label encoding (0,1,..,6)\n",
    "def lab_encode(dataset, le):\n",
    "    new_ds = dataset\n",
    "    new_ds[\"dx\"] = le.fit_transform(dataset[\"dx\"])  \n",
    "    return new_ds\n",
    "\n",
    "\n",
    "# decodifica colonna dx\n",
    "def lab_decode(dataset, le):\n",
    "    new_ds = dataset\n",
    "    new_ds[\"dx\"] = le.inverse_transform(dataset[\"dx\"])  \n",
    "    return new_ds\n",
    "\n",
    "\n",
    "# conteggio immagini da generare dal dataset, risultato salvato in aug_size\n",
    "def stats(dataset, aug_size):\n",
    "    labels = set(dataset['dx'])\n",
    "    for label in labels:\n",
    "        print(\"class \", str(label), ':\\t', str(dataset[dataset['dx']==label]['dx'].count()))\n",
    "        x = dataset[dataset['dx']==label]['dx'].count()\n",
    "        y = dataset[dataset['dx']==5]['dx'].count()\n",
    "        value = math.floor((y-x)/x)\n",
    "        print(\"ugmented per image: \", str(value), \"\\n\")\n",
    "        aug_size[label] = value\n",
    "        \n",
    "        \n",
    "# apre il dataset originale, toglie le features superflue e lo ritorna insieme all'array delle labels\n",
    "def initialize_dataset():\n",
    "    dataset = pd.read_csv(csv_path, encoding = \"ISO-8859-1\")\n",
    "    labels = set(dataset[\"dx\"])\n",
    "    new_ds = pd.DataFrame(dataset)\n",
    "    columns=[\"lesion_id\", \"dx_type\", \"age\", \"sex\", \"localization\"]\n",
    "    new_ds = new_ds.drop(columns=columns, axis=0)\n",
    "    return new_ds, labels\n",
    "\n",
    "\n",
    "# dall'array di nomi (es. dataset[\"image_id\"]) ritorna l'array d'immagini\n",
    "def load_images(array):\n",
    "    images = list()\n",
    "    #print(array.iloc[0])\n",
    "    for index in range(0,len(array)):\n",
    "        #print(index.type())\n",
    "        img_id = array.iloc[index]\n",
    "        elem = os.path.join(image_path, img_id)\n",
    "        elem = elem + \".jpg\"\n",
    "        img = cv2.imread(elem)\n",
    "        images.append(np.asarray(img))\n",
    "    return np.asarray(images)\n",
    "\n",
    "\n",
    "#  ritorna la parte di dataset che nel nome contiene il nome delle tuple di originale (originale è un dataset senza immagini aumentate)\n",
    "# (usato solo dopo aver partizionato originale)\n",
    "def estendi(dataset, originale):\n",
    "    res = pd.DataFrame()\n",
    "    for index2 in range(len(originale)):\n",
    "        temp = dataset[dataset[\"image_id\"].str.contains(originale.iloc[index2][\"image_id\"])]\n",
    "        res = res.append(temp)\n",
    "        if index2 % 1000 == 0:\n",
    "            print(index2)\n",
    "    return res\n",
    "\n",
    "\n",
    "# ritorna le 2 partizioni del dataframe (che non deve essere esteso) di fattori factor e 1-factor\n",
    "# es. factor = 0.8\n",
    "def partiziona(dataframe, factor):\n",
    "    part1 = pd.DataFrame()  # factor originali\n",
    "    part2 = pd.DataFrame()  # (1-factor) originali\n",
    "    for elem in range(7):\n",
    "        n = dataframe[dataframe['dx']==elem]['dx'].count() \n",
    "        p8 = int(n*factor)\n",
    "        print(\"n di tipo \", elem, \":\\t\", n, \"\\tandranno in part1:\\t\", p8)\n",
    "        blocco = dataframe[dataframe['dx']==elem]\n",
    "        blocco1 = blocco.sample(n=p8)\n",
    "        part1 = part1.append(blocco1)\n",
    "        part2 = part2.append(blocco.drop(blocco1.index))\n",
    "    print(\"size part1: \", len(part1))\n",
    "    print(\"size part2: \", len(part2))\n",
    "    return part1, part2\n",
    "\n",
    "\n",
    "# recupero dataset originale (senza immagini aumentate) dal dataset completo\n",
    "def only_orig(dataset):\n",
    "    reduced = pd.DataFrame()\n",
    "    for index in range(len(dataset)):\n",
    "        if len(dataset.iloc[index][\"image_id\"]) == 12:\n",
    "            reduced = reduced.append(dataset.iloc[index])\n",
    "    return reduced\n",
    "\n",
    "# a seconda della direzione sposta le immagini dentro oppure fuori le cartelle classi (0,...,6) partendo dalla loro madre\n",
    "def dir_game(dataset, out=0, cartella='..\\..\\skin-cancer-mnist-ham10000\\HAM10000_images_part_1\\\\'):\n",
    "    for index in range(len(dataset)):\n",
    "        img=dataset.iloc[index][\"image_id\"]\n",
    "        source = cartella + img +'.jpg'\n",
    "        dx =str(dataset.iloc[index][\"dx\"])\n",
    "        dest = cartella + dx + '\\\\' + img + '.jpg'\n",
    "        if out == 0:\n",
    "            os.replace(source, dest)         # metto le immagini dentro le cartelle classi\n",
    "        elif out == 1:\n",
    "            os.replace(dest, source)         # metto le immagini fuori le cartelle classi\n",
    "        else:\n",
    "            print(\"input error\")\n",
    "            break\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variabili globali\n",
    "#### GIUSEPPE\n",
    "#image_path = '..\\\\..\\skin-cancer-mnist-ham10000\\HAM10000_images_part_1'   #path immagini 600x450\n",
    "image_path = '..\\\\..\\\\Untitled_Folder'      # path immagini 200x150\n",
    "csv_path = 'HAM10000_metadata.csv'\n",
    "csv_completo = 'dataframe_completo.csv'     # in 10016 c'è una riga fake\n",
    "csv_completo_2 = 'dataframe_completo_2.csv'\n",
    "csv_orig = '/csv/dataframe_originale.csv'   # csv su colab senza immagini aumentate\n",
    "aug_dir = '..\\\\..\\\\aug_dir'                 # path delle immagini aumentate\n",
    "\n",
    "#### FABIO\n",
    "# image_path = '..\\skin-cancer-mnist-ham10000\\HAM10000_images_part_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age\n",
       "age  1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlazione standard tra le colonne ############################################NON FUNZIONA\n",
    "df = pd.read_csv(csv_path, encoding = \"ISO-8859-1\")\n",
    "df.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>ISIC_0033084</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>ISIC_0033550</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>ISIC_0033536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>ISIC_0032854</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>ISIC_0032258</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10015 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_id  dx\n",
       "0      ISIC_0027419   2\n",
       "1      ISIC_0025030   2\n",
       "2      ISIC_0026769   2\n",
       "3      ISIC_0025661   2\n",
       "4      ISIC_0031633   2\n",
       "...             ...  ..\n",
       "10010  ISIC_0033084   0\n",
       "10011  ISIC_0033550   0\n",
       "10012  ISIC_0033536   0\n",
       "10013  ISIC_0032854   0\n",
       "10014  ISIC_0032258   4\n",
       "\n",
       "[10015 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INIZIALIZZAZIONE\n",
    "\n",
    "#creazione dataframe in memoria con colonne [image_id, dx]\n",
    "ds, labels = initialize_dataset()\n",
    "\n",
    "\n",
    "# label encoding delle labels (dx)\n",
    "encoder = preproc.LabelEncoder()\n",
    "encoded = lab_encode(ds, encoder)\n",
    "encoded = encoded.sort_index()\n",
    "\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class  0 :\t 327\n",
      "ugmented per image:  19 \n",
      "\n",
      "class  1 :\t 514\n",
      "ugmented per image:  12 \n",
      "\n",
      "class  2 :\t 1099\n",
      "ugmented per image:  5 \n",
      "\n",
      "class  3 :\t 115\n",
      "ugmented per image:  57 \n",
      "\n",
      "class  4 :\t 1113\n",
      "ugmented per image:  5 \n",
      "\n",
      "class  5 :\t 6705\n",
      "ugmented per image:  0 \n",
      "\n",
      "class  6 :\t 142\n",
      "ugmented per image:  46 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# analisi dei valori per data augmentation\n",
    "aug_size = [0,0,0,0,0,0,0]\n",
    "stats(encoded, aug_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA AUGMENTATION\n",
    "\n",
    "# Create a data generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    #brightness_range=(0.9,1.1),\n",
    "    fill_mode='nearest')\n",
    "\n",
    "##### creazione immagini augmented\n",
    "\n",
    "# note that we are not augmenting class 'nv', cioè la 5\n",
    "class_list = ['0','1','2','3','4','6']\n",
    "\n",
    "img_dir = os.path.join(aug_dir, 'img_dir')    \n",
    "\n",
    "# Choose a class\n",
    "for img_class in class_list:    \n",
    "    # creazione cartelle contenenti le augmented\n",
    "    dst_class_dir = os.path.join(img_dir, img_class)\n",
    "    os.mkdir(dst_class_dir)   # cartelle da 0 a 6 dentro aug_dir/img_dir\n",
    "    \n",
    "    # list all images in that directory\n",
    "    src_class_dir = os.path.join('..\\\\skin-cancer-mnist-ham10000\\\\HAM10000_images_part_1', img_class)\n",
    "    img_list = os.listdir(src_class_dir) # qui le immagini sono già nelle proprie cartelle, cioè in skin-cancer-mnist-ham10000/HAM10000_images_part_1/0, ...,6\n",
    "    print('#img: '+ str(len(img_list)))\n",
    "    \n",
    "    # per ogni immagine devo creare le augmented\n",
    "    for fname in img_list:\n",
    "        fpath = os.path.join(src_class_dir, fname) # path completo dell'immagine src\n",
    "        img = Image.open(fpath)  # this is a PIL image\n",
    "        x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "        x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "        \n",
    "        prefix = fname.replace(\".jpg\", \"\")\n",
    "        # the .flow() command below generates batches of randomly transformed images e lo faccio fino a quando non arrivo all'aug_size\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1, save_to_dir=dst_class_dir, save_prefix=prefix , save_format='jpg'):\n",
    "            i += 1\n",
    "            if i > aug_size[int(img_class)]:\n",
    "                break\n",
    "        del x\n",
    "        img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## aggiornamento nuovo dataset con le immagini aumentate\n",
    "img_dir = os.path.join(aug_dir, 'img_dir') \n",
    "classes = os.listdir(img_dir)                  # elenco delle cartelle (da 0 a 6)\n",
    "\n",
    "columns = encoded.columns\n",
    "tupla = pd.DataFrame(columns=columns)          # dataset vuoto, alla fine dei cicli for conterrà tutte le nuove immagini aumentate con dx cartella madre\n",
    "index = 10015\n",
    "\n",
    "for elem1 in classes:\n",
    "    class_dir = os.path.join(img_dir, elem1)\n",
    "    images = os.listdir(class_dir)\n",
    "    for elem2 in images:\n",
    "        elem2 = elem2.replace('.jpg', '')\n",
    "        tupla = tupla.append({'image_id': elem2, 'dx': int(elem1)}, ignore_index=True)\n",
    "        \n",
    "encoded2 = encoded.append(tupla)\n",
    "encoded2.to_csv(csv_completo, index=False)     # il csv con la riga 10016 fake           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescaling immagini\n",
    "src_path = \"../../skin-cancer-mnist-ham10000/HAM10000_images_part_1\"\n",
    "dst_path = \"../../Untitled Folder\"\n",
    "size1=(200, 150)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for fname in os.listdir(src_path):\n",
    "    img_rsz = Image.open(os.path.join(src_path, fname)).resize(size1)\n",
    "    img_rsz.save(os.path.join(dst_path, fname))\n",
    "    count = count + 1\n",
    "    if count % 5000 == 0:\n",
    "        print(\"resizate \" + str(count) + \" immagini\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
